{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#(X) ideally, want 1 CSV per channel\n",
    "#(X) may have to split by time as well if too large\n",
    "\n",
    "# analysis from different denominators. from offered, accept, qualified, bv, ... for optimizing origination\n",
    "# from funded from optimizing loan performance\n",
    "# validate that all rows have a clarity report\n",
    "\n",
    "#(X) blocked on fixing missing clarity reports for 201s -- unblocked, need leadzeppelin.offers\n",
    "#(X) a third of accepted leads in bridge -- is this expected? looks right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(devtools)\n",
    "# install_github(\n",
    "#     'jasonchang2018/opploansanalytics',\n",
    "#     auth_token = Sys.getenv('GITHUB_PAT_OPPLOANSANALYTICS')\n",
    "# )\n",
    "\n",
    "# options(java.parameters = \"-Xmx8048m\")\n",
    "\n",
    "library(opploansanalytics)\n",
    "load.packages()\n",
    "\n",
    "library(mlr)\n",
    "library(pdp)\n",
    "library(vip)\n",
    "library(reshape2)\n",
    "library(furrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#### Clarity Field Analysis ####\n",
    "clarityAnalysis = function () {\n",
    "\n",
    "# ####  Clarity Report Type Validation  ####\n",
    "# test %>%\n",
    "#     filter(\n",
    "#         ! report_received %>% str_detect('(?:FWB)?Leads01.*')\n",
    "#     ) %>% \n",
    "#     transmute(\n",
    "#         lead_id,\n",
    "#         report_received,\n",
    "#         report_requested,\n",
    "#         lead_time,\n",
    "#         report_time,\n",
    "#         lead.date = lead_time %>% as.Date(),\n",
    "#         report.date = report_time %>% as.Date(),\n",
    "#         diff = lead.date - report.date\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         diff\n",
    "#     )\n",
    "# #     ) %T>%\n",
    "# #     write.csv(\"..\\\\docs\\\\received-not-leads01.csv\")\n",
    "\n",
    "# test %>% group_by(report_received) %>% summarize(n = n()) %>% ungroup() %>% arrange(desc(n))\n",
    "\n",
    "#### Get Clarity Data\n",
    "\n",
    "####  Existing Fields  ####\n",
    "getClarityFields = function () {\n",
    "\n",
    "    a <- queryReporting(\n",
    "    \"\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        lde4.leads\n",
    "    where\n",
    "        --lead_time >= now()::date - '5 days'::interval\n",
    "        lead_id = '99f418da-8b66-471e-9586-f4112718ed21'\n",
    "    limit 100\n",
    "    \"\n",
    "    ) %>%\n",
    "        select(\n",
    "            lead_id,\n",
    "            clarity_report,\n",
    "            accepted\n",
    "        )\n",
    "\n",
    "    b <- a %>%\n",
    "        filter(\n",
    "            !is.na(clarity_report)\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            json.df = clarity_report %>% \n",
    "                map(\n",
    "                    .f = ~ .x %>%\n",
    "                        fromJSON() %>%\n",
    "                        .$xml_response %>% \n",
    "                        unlist() %>% \n",
    "                        as.data.frame(\n",
    "                            stringsAsFactors = FALSE\n",
    "                        ) %>% \n",
    "                        t()\n",
    "                )\n",
    "        )\n",
    "\n",
    "    all.fields <<- b %>%\n",
    "        filter(\n",
    "            lead_id == '99f418da-8b66-471e-9586-f4112718ed21'\n",
    "        ) %>%\n",
    "        .$clarity_report %>%\n",
    "        fromJSON(\n",
    "        ) %>% \n",
    "        .$xml_response %>% \n",
    "        unlist(\n",
    "        ) %>% \n",
    "        as.data.frame(\n",
    "            stringsAsFactors = FALSE\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            var = 'key'\n",
    "        ) %>% \n",
    "        rename(\n",
    "            value = \".\"\n",
    "        )\n",
    "\n",
    "    inquiry.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^inquiry\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                key %in% paste0(\n",
    "                    'inquiry.',\n",
    "                    c(\n",
    "                        'ofac_match',\n",
    "                        'ofac_score',\n",
    "                        'social_security_valid',\n",
    "                        'social_security_deceased',\n",
    "                        'ssn_distinct_first_last_name_count',\n",
    "                        'paycheck_direct_deposit',\n",
    "                        'bank_routing_valid',\n",
    "                        'inquiry_purpose_type'\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "    ccr.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^clear_credit_risk\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                !key %>% str_detect('inquiries\\\\.member_id') &\n",
    "                !key %>% str_detect('inquiry_received_at') &\n",
    "                !key %>% str_detect('inquiry_purpose_type') &\n",
    "                !key %>% str_detect('inquiry_tradeline_type') &\n",
    "                !key %>% str_detect('tradelines\\\\..*') &\n",
    "                !key %>% str_detect('stabilities\\\\..*') &\n",
    "                !key %>% str_detect('experian_attribute\\\\..*') &\n",
    "                !key %>% str_detect('description') &\n",
    "                !key %>% str_detect('full_name') &\n",
    "                !key %>% str_detect('code') &\n",
    "                !key %>% str_detect('date') &\n",
    "                !key %>% str_detect('first') &\n",
    "                !key %>% str_detect('48')\n",
    "#                 !key %>% str_detect('inquiry_purpose_type') & #keep\n",
    "#                 !key %>% str_detect('inquiry_tradeline_type') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.account_opened') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.highest_credit') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.amount_past_due') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.current_balance') & #keep\n",
    "            )\n",
    "\n",
    "    crh.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^clear_recent_history\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                !key %>% str_detect('tradeline_stabilities') &\n",
    "                !key %>% str_detect('date') &\n",
    "                !key %>% str_detect('name') &\n",
    "                !key %>% str_detect('\\\\d+')\n",
    "            )\n",
    "\n",
    "    rbind(\n",
    "        inquiry.fields,\n",
    "        ccr.fields,\n",
    "        crh.fields\n",
    "    ) %>% .$key\n",
    "    \n",
    "}\n",
    "\n",
    "####  Pull Test Clarity Report  ####\n",
    "test = queryReporting(\n",
    "\"\n",
    "select\n",
    "\n",
    "    --  Identifiers --\n",
    "    lde.lead_id\n",
    "    , lde.leadofferid\n",
    "    , lde.passthru_lead_offer_id\n",
    "    , lde.lead_time at time zone 'America/Chicago' as lead_time\n",
    "    , lde.partnerid\n",
    "\n",
    "    --  Credit  --\n",
    "    , case when lde.clarity_report notnull then TRUE else FALSE end as has_clarity\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'inquiry_received_at' as report_time\n",
    "    , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'received' as report_received\n",
    "    , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'requested_file' as report_requested\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ofac_score' as ofac_score\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'paycheck_direct_deposit' as paycheck_direct_deposit\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ssn_distinct_first_last_name_count' as ssn_distinct_first_last_name_count\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'score' as ccr_score\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'clarity_seen' as ccr_clarity_seen\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_loans' as ccr_number_of_loans\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_bank_accounts' as ccr_number_of_bank_accounts\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'highest_number_of_days_past_due' as ccr_highest_number_of_days_past_due\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'current_inquiry_cluster_position' as ccr_current_inquiry_cluster_position\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_last_loan_charged_off' as ccr_days_since_last_loan_charged_off\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_inquiry_previously_seen' as ccr_days_since_inquiry_previously_seen\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_employers_last_six_months' as ccr_number_of_employers_last_six_months\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'loans_in_collections' as srh_loans_in_collections\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'spml_average_rollovers' as srh_spml_average_rollovers\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'amount_loans_charged_off' as srh_amount_loans_charged_off\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_opened_in_the_last_year' as srh_online_loan_opened_in_the_last_year\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_inquiry_in_the_last_thirty_days' as srh_online_loan_inquiry_in_the_last_thirty_days\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'ninety_days_ago' as ticrh_ninety_days_ago\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'twentyfour_hours_ago' as ticrh_twentyfour_hours_ago\n",
    "\n",
    "\n",
    "    from\n",
    "        lde4.leads as lde\n",
    "    inner join\n",
    "        cloudlending.advertising_method as c_am\n",
    "        on lde.partnerid = c_am.external_id\n",
    "        and c_am.name = 'LenderEdge 4' \n",
    "    where\n",
    "        lde.accepted = TRUE\n",
    "        and lde.lead_time >= '2020-03-09'::date\n",
    "    limit 1000\n",
    "\"\n",
    ")\n",
    "\n",
    "####  Identify Data Types  ####\n",
    "not.features = c(\n",
    "    'lead_id',\n",
    "    'leadofferid',\n",
    "    'passthru_lead_offer_id',\n",
    "    'lead_time',\n",
    "    'partnerid',\n",
    "    'has_clarity',\n",
    "    'report_time',\n",
    "    'report_received',\n",
    "    'report_requested'\n",
    ")\n",
    "\n",
    "boolean.features = c(\n",
    "    'paycheck_direct_deposit',\n",
    "    'ccr_hit',\n",
    "    'ccr_clarity_seen',\n",
    "    'srh_online_loan_opened_in_the_last_year',\n",
    "    'srh_online_loan_inquiry_in_the_last_thirty_days'\n",
    ")\n",
    "\n",
    "numeric.features = colnames(test)[\n",
    "    which(\n",
    "        !colnames(test) %in% c(\n",
    "            boolean.features,\n",
    "            not.features,\n",
    "            'ccr_worst_payment_rating_null',\n",
    "            'ccr_worst_payment_rating_plus',\n",
    "            'ccr_worst_payment_rating_zero',\n",
    "            'ccr_worst_payment_rating_hash',\n",
    "            'ccr_worst_payment_rating_else',\n",
    "            'ccr_worst_payment_rating'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "processed.features = c(\n",
    "    'ccr_worst_payment_rating',\n",
    "    'ccr_days_since_last_loan_charged_off',\n",
    "    'ccr_days_since_last_loan_paid_off',\n",
    "    'ccr_days_since_last_ontime_payment',\n",
    "    'ccr_days_since_last_loan_payment',\n",
    "    'ccr_days_since_last_loan_opened'\n",
    ")\n",
    "\n",
    "impute.median = c(\n",
    "    'ccr_days_since_previous_bank_account_previously_seen',\n",
    "    'ccr_days_since_reported_income_previously_seen',\n",
    "    'ccr_days_since_inquiry_previously_seen',\n",
    "    'ccr_highest_number_of_days_past_due',\n",
    "    'paycheck_direct_deposit'\n",
    ")\n",
    "\n",
    "impute.mean = c(\n",
    "    'ccr_number_of_loans',\n",
    "    'ccr_number_of_bank_accounts',\n",
    "    'ccr_number_of_loans_paid_off',\n",
    "    'ccr_number_of_loans_paid_off',\n",
    "    'ccr_number_of_loans_past_due',\n",
    "    'ccr_current_inquiry_cluster_position',\n",
    "    'ccr_number_of_loans_current_and_open',\n",
    "    'ccr_number_of_employers_last_six_months',\n",
    "    'ccr_score'\n",
    ")\n",
    "\n",
    "correlated.features.numeric = c(\n",
    "    'icrh_ten_minutes_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_twenty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "    'icrh_thirty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "    'icrh_one_hour_ago',                                       #ccr_current_inquiry_cluster_position\n",
    "    'icrh_twentyfour_hours_ago',                               #ccr_current_inquiry_cluster_position\n",
    "    'icrh_seven_days_ago',                                     #ccr_current_inquiry_cluster_position\n",
    "    'icrh_thirty_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_ninety_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_recent_history_current_inquiry_cluster_position',    #ccr_current_inquiry_cluster_position\n",
    "    \n",
    "    'ticrh_seven_days_ago',                                    #ticrh_twentyfour_hours_ago\n",
    "    'ticrh_thirty_days_ago',                                   #ticrh_twentyfour_hours_ago\n",
    "    \n",
    "    'ccr_number_of_loans_paid_off',                            #ccr_number_of_loans\n",
    "    'ccr_number_of_loans_past_due',                            #ccr_number_of_loans\n",
    "    'ccr_number_of_loans_current_and_open',                    #ccr_number_of_loans,\n",
    "    'ccr_days_since_reported_income_previously_seen',          #ccr_days_since_inquiry_previously_seen\n",
    "    'ccr_days_since_previous_bank_account_previously_seen',    #ccr_days_since_inquiry_previously_seen\n",
    "    \n",
    "    'srh_amount_loans_in_collections',                         #srh_loans_in_collections\n",
    "    'srh_days_with_open_loans_in_the_last_ninety_days',        #srh_loans_in_collections\n",
    "    'srh_days_with_open_loans_in_the_last_year'                #srh_loans_in_collections\n",
    ")\n",
    "\n",
    "correlated.features.logical = c(\n",
    "    'ccr_hit',                                                 #ccr_clarity_seen\n",
    "    'ccr_worst_payment_rating_plus',                           #ccr_has_previous_loan_charged_off\n",
    "    'ccr_worst_payment_rating_null',                           #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_loan_payment',                           #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_ontime_payment',                         #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_loan_paid_off',                          #ccr_has_previous_loan_opened   \n",
    "    'ccr_has_previous_loan_charged_off'                        #ccr_has_previous_loan_opened  \n",
    ")\n",
    "\n",
    "#### Convert Data Types\n",
    "\n",
    "####  Convert Data Types  ####\n",
    "test.clean = test %>%\n",
    "    select(\n",
    "        -not.features\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = boolean.features[which(! boolean.features %in% correlated.features.numeric)],\n",
    "        .funs = as.logical\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = numeric.features[which(! numeric.features %in% correlated.features.numeric)],\n",
    "        .funs = as.numeric\n",
    "    ) %>% \n",
    "    mutate(\n",
    "        ccr_worst_payment_rating_null = is.na(ccr_worst_payment_rating),\n",
    "        ccr_worst_payment_rating_plus = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '+',\n",
    "        ccr_worst_payment_rating_zero = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '0',\n",
    "        ccr_worst_payment_rating_hash = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '#',\n",
    "        ccr_worst_payment_rating_else = !(\n",
    "            ccr_worst_payment_rating_plus |\n",
    "            ccr_worst_payment_rating_zero |\n",
    "            ccr_worst_payment_rating_hash |\n",
    "            ccr_worst_payment_rating_null\n",
    "        ),\n",
    "        \n",
    "        ccr_has_previous_loan_charged_off = ccr_days_since_last_loan_charged_off %>%\n",
    "            getClarityMapping()$convertDaysChargedOff(),\n",
    "        ccr_has_previous_loan_paid_off = ccr_days_since_last_loan_paid_off %>% \n",
    "            getClarityMapping()$convertDaysPaidOff(),\n",
    "        ccr_has_previous_ontime_payment = ccr_days_since_last_ontime_payment %>% \n",
    "            getClarityMapping()$convertDaysOntimePayment(),\n",
    "        ccr_has_previous_loan_payment = ccr_days_since_last_loan_payment %>% \n",
    "            getClarityMapping()$convertDaysAnyPayment(),\n",
    "        ccr_has_previous_loan_opened = ccr_days_since_last_loan_opened %>% \n",
    "            getClarityMapping()$convertDaysLoanOpened()\n",
    "        \n",
    "        \n",
    "    ) %>%\n",
    "    select(\n",
    "        -processed.features\n",
    "    )\n",
    "# test.clean %>% str()\n",
    "\n",
    "#### Impute\n",
    "\n",
    "####  Examine Values in Field  ####\n",
    "field = quo(paycheck_direct_deposit)\n",
    "\n",
    "test.clean[[quo_name(field)]] %>% median(na.rm = TRUE)\n",
    "test.clean[[quo_name(field)]] %>% mean(na.rm = TRUE)\n",
    "\n",
    "test %>%\n",
    "    group_by(\n",
    "#         var = !!field %>% as.numeric\n",
    "        var = !!field\n",
    "    ) %>% \n",
    "    summarize(\n",
    "        n = n()\n",
    "    ) %>%\n",
    "    ungroup() %>%\n",
    "#     filter(\n",
    "#         !is.na(var)\n",
    "#         var < 100\n",
    "#     ) %>% \n",
    "    arrange(\n",
    "#         desc(n)\n",
    "        var\n",
    "#     )\n",
    "    ) %>% ggplot(aes(x = var, y = n)) + geom_bar(stat = 'identity')\n",
    "\n",
    "####  Impute and/or Remove Missing Values  ####\n",
    "test.impute.value = test.clean %>%\n",
    "    mutate_at(\n",
    "        .vars = impute.median[ which(! impute.median %in% correlated.features.numeric) ],\n",
    "        .funs = ~ .x %>%\n",
    "            replace_na(\n",
    "                replace = .x %>% median(na.rm = TRUE)\n",
    "            )\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = impute.mean[ which(! impute.mean %in% correlated.features.numeric) ],\n",
    "        .funs = ~ .x %>%\n",
    "            replace_na(\n",
    "                replace = .x %>% mean(na.rm = TRUE)\n",
    "            )\n",
    "    ) %>% \n",
    "    mutate(\n",
    "        paycheck_direct_deposit = paycheck_direct_deposit %>% as.logical()\n",
    "    )\n",
    "\n",
    "test.impute = test.impute.value %>% \n",
    "    filter(\n",
    "        apply(\n",
    "            X = test.impute.value,\n",
    "            FUN = function (x) { x %>% is.na() %>% sum() },\n",
    "            MARGIN = 1\n",
    "        ) == 0\n",
    "    )\n",
    "\n",
    "#### Numeric Collinearity\n",
    "\n",
    "####  Calculate Correlation Matrix (Numeric)  ####\n",
    "test.numeric.cor = test.impute %>%\n",
    "    select(\n",
    "        numeric.features[ which(!numeric.features %in% processed.features)]\n",
    "    ) %>% \n",
    "    cor()\n",
    "\n",
    "test.numeric.cor[upper.tri(test.numeric.cor)] = NA\n",
    "test.numeric.cor.upper = test.numeric.cor %>% melt(na.rm = TRUE)\n",
    "\n",
    "# ####  Sum Missing (NA) Values for Numeric  ####\n",
    "# apply(\n",
    "# #     X = test.clean %>%\n",
    "#     X = test.impute %>%\n",
    "#         select(\n",
    "#             numeric.features[ which(!numeric.features %in% c(processed.features, correlated.features.numeric)) ]\n",
    "#         ),\n",
    "#     FUN = function (x) { is.na(x) %>% sum() },\n",
    "#     MARGIN = 2\n",
    "# ) %>% \n",
    "# as.data.frame() %>% select(n = '.') %>% rownames_to_column('field') %>% arrange(desc(n))\n",
    "\n",
    "# ####  Find / Remove Collinear Features (Numeric)  ####\n",
    "# correlated.features.numeric = c(\n",
    "#     'icrh_ten_minutes_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_twenty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_thirty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_one_hour_ago',                                       #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_twentyfour_hours_ago',                               #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_seven_days_ago',                                     #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_thirty_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_ninety_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_recent_history_current_inquiry_cluster_position',    #ccr_current_inquiry_cluster_position\n",
    "    \n",
    "#     'ticrh_seven_days_ago',                                    #ticrh_twentyfour_hours_ago\n",
    "#     'ticrh_thirty_days_ago',                                   #ticrh_twentyfour_hours_ago\n",
    "    \n",
    "#     'ccr_number_of_loans_paid_off',                            #ccr_number_of_loans\n",
    "#     'ccr_number_of_loans_past_due',                            #ccr_number_of_loans\n",
    "#     'ccr_number_of_loans_current_and_open',                    #ccr_number_of_loans,\n",
    "#     'ccr_days_since_reported_income_previously_seen',          #ccr_days_since_inquiry_previously_seen\n",
    "#     'ccr_days_since_previous_bank_account_previously_seen',    #ccr_days_since_inquiry_previously_seen\n",
    "    \n",
    "#     'srh_amount_loans_in_collections',                         #srh_loans_in_collections\n",
    "#     'srh_days_with_open_loans_in_the_last_ninety_days',        #srh_loans_in_collections\n",
    "#     'srh_days_with_open_loans_in_the_last_year'                #srh_loans_in_collections\n",
    "# )\n",
    "\n",
    "# test.numeric.cor.upper.removed = test.numeric.cor.upper %>% \n",
    "#     filter(\n",
    "#         Var1 != Var2\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         desc(value)\n",
    "#     ) %>% \n",
    "#     filter(\n",
    "#         ! Var1 %in% correlated.features.numeric &\n",
    "#         ! Var2 %in% correlated.features.numeric\n",
    "#     ) %>% \n",
    "# #     group_by(\n",
    "# #         Var1\n",
    "# #     ) %>% \n",
    "# #     summarize(\n",
    "# #         n = n(),\n",
    "# #         total.cor = sum(value^2)\n",
    "# #     ) %>% \n",
    "# #     ungroup() %>% \n",
    "#     arrange(\n",
    "# #         total.cor %>% desc\n",
    "#         value %>% desc\n",
    "#     )\n",
    "\n",
    "# test.numeric.cor.upper.removed %T>%\n",
    "#     head() %>% \n",
    "#     ggplot(\n",
    "#         mapping = aes(\n",
    "#             x = Var1,\n",
    "#             y = Var2,\n",
    "#             fill = value\n",
    "#         )\n",
    "#     ) +\n",
    "#     geom_tile(\n",
    "#         color = 'white'\n",
    "#     ) +\n",
    "#     scale_fill_gradient2(\n",
    "#         low = \"blue\",\n",
    "#         high = \"red\",\n",
    "#         mid = \"white\", \n",
    "#         midpoint = 0,\n",
    "#         limit = c(-1,1),\n",
    "#         space = \"Lab\", \n",
    "#         name=\"Pearson\\nCorrelation\"\n",
    "#     ) +\n",
    "#     theme_minimal() +\n",
    "#     theme(\n",
    "#         axis.text.x = element_text(\n",
    "#             angle = -45,\n",
    "#             hjust = 0\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#### Boolean Collinearity\n",
    "\n",
    "####  Calculate Correlation Matrix (Boolean)  ####\n",
    "test.logical.cor = test.impute %>%\n",
    "    select(\n",
    "        -c(numeric.features[ which(!numeric.features %in% processed.features)])\n",
    "    ) %>%\n",
    "    cor()\n",
    "\n",
    "test.logical.cor[upper.tri(test.logical.cor)] = NA\n",
    "test.logical.cor.upper = test.logical.cor %>% melt(na.rm = TRUE)\n",
    "\n",
    "# ####  Find / Remove Collinear Features (Logical)  ####\n",
    "# correlated.features.logical = c(\n",
    "#     'ccr_hit',                               # ccr_clarity_seen\n",
    "#     'ccr_worst_payment_rating_plus',         # ccr_has_previous_loan_charged_off\n",
    "#     'ccr_worst_payment_rating_null',         # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_loan_payment',         # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_ontime_payment',       # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_loan_paid_off',        # ccr_has_previous_loan_opened   \n",
    "#     'ccr_has_previous_loan_charged_off'      # ccr_has_previous_loan_opened  \n",
    "# )\n",
    "\n",
    "# test.logical.cor.upper.removed = test.logical.cor.upper %>% \n",
    "#     filter(\n",
    "#         Var1 != Var2\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         desc(value)\n",
    "# #         value\n",
    "#     ) %>% \n",
    "#     filter(\n",
    "#         ! Var1 %in% correlated.features.logical &\n",
    "#         ! Var2 %in% correlated.features.logical\n",
    "# #     ) %>% \n",
    "# #     group_by(\n",
    "# #         Var1\n",
    "# #     ) %>% \n",
    "# #     summarize(\n",
    "# #         n = n(),\n",
    "# #         total.cor = sum(value^2)\n",
    "# #     ) %>% \n",
    "# #     ungroup() %>% \n",
    "# #     arrange(\n",
    "# #         total.cor %>% desc\n",
    "#     )\n",
    "\n",
    "# test.logical.cor.upper.removed\n",
    "\n",
    "# test.logical.cor.upper.removed %>%\n",
    "#     ggplot(\n",
    "#         mapping = aes(\n",
    "#             x = Var1,\n",
    "#             y = Var2,\n",
    "#             fill = value\n",
    "#         )\n",
    "#     ) +\n",
    "#     geom_tile(\n",
    "#         color = 'white'\n",
    "#     ) +\n",
    "#     scale_fill_gradient2(\n",
    "#         low = \"blue\",\n",
    "#         high = \"red\",\n",
    "#         mid = \"white\", \n",
    "#         midpoint = 0,\n",
    "#         limit = c(-1,1),\n",
    "#         space = \"Lab\", \n",
    "#         name=\"Pearson\\nCorrelation\"\n",
    "#     ) +\n",
    "#     theme_minimal() +\n",
    "#     theme(\n",
    "#         axis.text.x = element_text(\n",
    "#             angle = -45,\n",
    "#             hjust = 0\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# getClarityMapping = function () {\n",
    "    \n",
    "#     convertInquiryPurposeType = function (purpose.code) {\n",
    "        \n",
    "#         case_when(\n",
    "#             purpose.code == 'AR' ~ 'New Credit',\n",
    "#             purpose.code == 'AS' ~ 'New Credit Soft',\n",
    "#             purpose.code == 'RA' ~ 'Account Review Soft',\n",
    "#             purpose.code == 'RP' ~ 'Consumer Inquiry Soft',\n",
    "#             purpose.code == 'CL' ~ 'Collection Inquiry',\n",
    "#             purpose.code == 'PC' ~ 'Pre-check Soft',\n",
    "#             purpose.code == 'MS' ~ 'Credit Monitor Soft',\n",
    "#             purpose.code == 'CC' ~ 'Check Cash',\n",
    "#             purpose.code == 'CS' ~ 'Collection Soft',\n",
    "#             purpose.code == 'PS' ~ 'Pre-screen Soft',\n",
    "#             purpose.code == 'IV' ~ 'Item Verification',\n",
    "#             purpose.code == 'IS' ~ 'Item Verification Soft',\n",
    "#             purpose.code == 'EH' ~ 'Employment',\n",
    "#             purpose.code == 'ES' ~ 'Employment Soft',\n",
    "#             purpose.code == 'LH' ~ 'Lease',\n",
    "#             purpose.code == 'LS' ~ 'Lease Soft',\n",
    "#             purpose.code == 'WS' ~ 'Written Authorization Soft',\n",
    "#             purpose.code == 'WH' ~ 'Written Authorization - Hard',\n",
    "#             purpose.code == 'PR' ~ 'Portfolio Review',\n",
    "#             purpose.code == 'PA' ~ 'Portfolio Acquisition',\n",
    "#             purpose.code == 'SP' ~ 'Subpoena',\n",
    "#             TRUE ~ 'Other'\n",
    "#         )\n",
    "#     }\n",
    "#     convertWorstPaymentRatingCCR = function (rating) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(rating) ~ 0,\n",
    "#             rating == '+' ~ 1,\n",
    "#             rating == '0' ~ 2,\n",
    "#             rating == '#' ~ 3,\n",
    "#             rating == '@' ~ 4,\n",
    "#             rating == 'X' ~ 5,\n",
    "#             rating == '4' ~ 6,\n",
    "#             rating == 'V' ~ 7,\n",
    "#             rating == 'W' ~ 8,\n",
    "#             rating == '1' ~ 9,\n",
    "#             rating == '5' ~ 10,\n",
    "#             rating == 'B' ~ 11,\n",
    "#             rating == 'L' ~ 12,\n",
    "#             rating == '7' ~ 13,\n",
    "#             rating == '8' ~ 14,\n",
    "#             rating == 'C' ~ 15,\n",
    "#             rating == 'D' ~ 16,\n",
    "#             rating == 'E' ~ 17,\n",
    "#             rating == 'H' ~ 18,\n",
    "#             rating == 'U' ~ 19,\n",
    "#             rating == 'Y' ~ 20,\n",
    "#             rating == 'Z' ~ 21,\n",
    "#             TRUE ~ 22\n",
    "#         )\n",
    "#     }\n",
    "#     convertDaysChargedOff = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysPaidOff = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysOntimePayment = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysAnyPayment = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysLoanOpened = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "    \n",
    "#     list(\n",
    "#         convertInquiryPurposeType = convertInquiryPurposeType,\n",
    "#         convertWorstPaymentRatingCCR = convertWorstPaymentRatingCCR,\n",
    "#         convertDaysChargedOff = convertDaysChargedOff,\n",
    "#         convertDaysPaidOff = convertDaysPaidOff,\n",
    "#         convertDaysOntimePayment = convertDaysOntimePayment,\n",
    "#         convertDaysAnyPayment = convertDaysAnyPayment,\n",
    "#         convertDaysLoanOpened = convertDaysLoanOpened\n",
    "#     )\n",
    "        \n",
    "# }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getDF = function (timestart = '2020-06-01', timeend = '2020-07-01', limit = NA, write = FALSE, admethod) {\n",
    "    \n",
    "    if (write) {\n",
    "        querySnowflake(paste0(\n",
    "            \"\n",
    "            select\n",
    "\n",
    "                ----  LDE  ----\n",
    "\n",
    "                leads.lead_id\n",
    "                , case  when leads.accepted = TRUE\n",
    "                        and  leads.apiversion = '5' \n",
    "                        then offers.lead_id \n",
    "                        when leads.accepted = FALSE\n",
    "                        and  leads.apiversion = '5'\n",
    "                        then leads.lead_id\n",
    "                        else NULL\n",
    "                        end  as lead_id_to_visine\n",
    "                , leads.lead_time\n",
    "                , extract(day from leads.lead_time) as lead_day\n",
    "\n",
    "                --  Outcome  --\n",
    "                , leads.apiversion\n",
    "                , case when leads.accepted = TRUE then 1 else 0 end as accepted\n",
    "                , leads.reason\n",
    "                , leads.code\n",
    "\n",
    "                --  Attributes  --\n",
    "                , leads.partnerid\n",
    "                , c_adm.name as admethod\n",
    "                , json_extract_path_text(leads.raw_lead, 'request.requestedLoanAmount') as requested_loan_amount\n",
    "                , coalesce(\n",
    "                    json_extract_path_text(leads.raw_lead, 'request.campaignID'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'request.campaignId'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'request.campaignid'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'request.campaign_id'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'request.click_id'),\n",
    "\n",
    "                    json_extract_path_text(leads.raw_lead, 'campaignID'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'campaignId'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'campaignid'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'campaign_id'),\n",
    "                    json_extract_path_text(leads.raw_lead, 'click_id')\n",
    "\n",
    "                ) as campaign_id\n",
    "\n",
    "                --  Income  --\n",
    "                , leads.grossmonthlyincome\n",
    "                , leads.incometype\n",
    "                , leads.payrollfrequency\n",
    "                , leads.payrolltype\n",
    "                , leads.lastpayrolldate\n",
    "\n",
    "                --  Identity  --\n",
    "                , leads.\\\"dateofbirth::text\\\" as dateofbirth\n",
    "                , floor((leads.lead_time::date - leads.\\\"dateofbirth::text\\\"::date)::numeric/365) as age\n",
    "                , leads.statecode\n",
    "\n",
    "                --  Employment  --\n",
    "                , leads.work_hiredate\n",
    "\n",
    "                --  Offer  --\n",
    "                , leads.leadofferid\n",
    "                , leads.offer_amount\n",
    "                , leads.offer_interestrate\n",
    "                , leads.offer_monthlypayment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ----  CLARITY  ----\n",
    "                , usages.id as usage_id\n",
    "                , usages.created_at as usage_time\n",
    "\n",
    "                , reports.id as cached_report_id\n",
    "                , reports.created_at as report_time\n",
    "                , reports.report_name\n",
    "\n",
    "                --  Inquiry --\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.inquiry.ofac_score') as ofac_score\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.inquiry.paycheck_direct_deposit') as paycheck_direct_deposit\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.inquiry.ssn_distinct_first_last_name_count') as ssn_distinct_first_last_name_count\n",
    "\n",
    "                --  CCR --\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.score') as ccr_score\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.number_of_loans') as ccr_number_of_loans\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.number_of_bank_accounts') as ccr_number_of_bank_accounts\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.highest_number_of_days_past_due') as ccr_highest_number_of_days_past_due\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.current_inquiry_cluster_position') as ccr_current_inquiry_cluster_position\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.days_since_last_loan_charged_off') as ccr_days_since_last_loan_charged_off\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.days_since_inquiry_previously_seen') as ccr_days_since_inquiry_previously_seen\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.number_of_employers_last_six_months') as ccr_number_of_employers_last_six_months\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_credit_risk.worst_payment_rating') as ccr_worst_payment_rating\n",
    "\n",
    "                --  CRH --\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.supplier_recent_history.summary_recent_history.loans_in_collections') as srh_loans_in_collections\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.supplier_recent_history.summary_recent_history.spml_average_rollovers') as srh_spml_average_rollovers\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.supplier_recent_history.summary_recent_history.amount_loans_charged_off') as srh_amount_loans_charged_off\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.supplier_recent_history.summary_recent_history.online_loan_opened_in_the_last_year') as srh_online_loan_opened_in_the_last_year\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.supplier_recent_history.summary_recent_history.online_loan_inquiry_in_the_last_thirty_days') as srh_online_loan_inquiry_in_the_last_thirty_days\n",
    "\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.inquiry_cluster_recent_history.total_inquiry_clusters_recent_history.ninety_days_ago') as ticrh_ninety_days_ago\n",
    "                , json_extract_path_text(coalesce(leads.clarity_report, reports.body), 'xml_response.clear_recent_history.inquiry_cluster_recent_history.total_inquiry_clusters_recent_history.twentyfour_hours_ago') as ticrh_twentyfour_hours_ago\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ----  CLOUDLENDING  ----\n",
    "\n",
    "                , bridge.app_id as application_bridge\n",
    "                , details.loanid\n",
    "                , details.application\n",
    "                , details.origination_id\n",
    "\n",
    "                --  Attributes --\n",
    "                , details.appldate\n",
    "                , details.adgrp\n",
    "\n",
    "                --  Decision --\n",
    "                , details.denygrp\n",
    "                , details.denial_reason\n",
    "\n",
    "                --  Funnel  --\n",
    "                , coalesce(details.newentered, 0) as newentered\n",
    "                , coalesce(details.bizrulespassed, 0) as bizrulespassed\n",
    "                , coalesce(details.qualified, 0) as qualified\n",
    "                , coalesce(details.bankverified, 0) as bankverified\n",
    "                , coalesce(details.passscorecardratecard, 0) as passscorecardratecard\n",
    "                , coalesce(details.contractsigned, 0) as contractsigned\n",
    "                , coalesce(details.cs_decisioned, 0) as cs_decisioned\n",
    "                , coalesce(details.funded, 0) as funded\n",
    "\n",
    "\n",
    "            from\n",
    "                loan_dw_prod.lead.leads_reporting as leads\n",
    "                inner join\n",
    "                    loan_dw_prod.cloudlending.advertising_method as c_adm\n",
    "                    on leads.partnerid = c_adm.external_id\n",
    "                    and c_adm.name = '\", admethod, \"'\n",
    "                left join\n",
    "                    loan_dw_prod.leadzeppelin.offers as offers\n",
    "                    on leads.lead_id = offers.id\n",
    "\n",
    "                left join\n",
    "                    loan_dw_prod.visine.report_usages as usages\n",
    "                    on case when leads.accepted = TRUE\n",
    "                            and  leads.apiversion = '5' \n",
    "                            then offers.lead_id \n",
    "                            when leads.accepted = FALSE\n",
    "                            and  leads.apiversion = '5'\n",
    "                            then leads.lead_id\n",
    "                            else NULL\n",
    "                            end = usages.lead_id\n",
    "                left join\n",
    "                    loan_dw_prod.visine.cached_reports as reports\n",
    "                    on usages.cached_report_id = reports.id\n",
    "                    and reports.report_name ilike '%leads01%'\n",
    "\n",
    "\n",
    "                left join\n",
    "                    periscope_de.periscope_views.apps_leads_bridge as bridge\n",
    "                    on leads.lead_id = bridge.lead_id\n",
    "                left join\n",
    "                    periscope_de.periscope_views.bizops_application_details as details\n",
    "                    on bridge.app_id = details.application\n",
    "\n",
    "\n",
    "            where\n",
    "                leads.lead_time >= '\", timestart, \"'\n",
    "                and leads.lead_time < '\", timeend, \"'\n",
    "            \",\n",
    "            if_else(\n",
    "                !is.na(limit),\n",
    "                paste0(\"limit \", limit),\n",
    "                \"\"\n",
    "            )\n",
    "        )) %>% \n",
    "        rename_all(\n",
    "            .funs = ~ .x %>% str_to_lower\n",
    "#         ) %T>% \n",
    "        ) %>% \n",
    "        write.csv(\n",
    "            paste0(\"..\\\\data-v2\\\\\", admethod %>% str_to_lower() %>% str_remove_all(\"\\\\s\"), \"-df-\", timestart, \".csv\"),\n",
    "            row.names = FALSE\n",
    "        )\n",
    "    } else {\n",
    "        suppressWarnings({suppressMessages({\n",
    "            read_csv(\"..\\\\data-v2\\\\clarity-df.csv\")\n",
    "        })})\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getAllDFs = function () {\n",
    "    \n",
    "    ##  Define month ranges and admethods\n",
    "    month.vec = seq.Date(\n",
    "        from = '2019-10-01' %>% as.Date(),\n",
    "        to = '2020-07-01' %>% as.Date(),\n",
    "        by = '1 month'\n",
    "    )\n",
    "    \n",
    "    admethod = c('LenderEdge 4', 'Even Financial 4', 'Monevo', 'Quin Street 4', 'LeadGroup', 'LeapTheory 4')\n",
    "    \n",
    "    \n",
    "    ##  Get all permutations of (date range) x admethod\n",
    "    all.pulls = merge(\n",
    "        x = data.frame(\n",
    "            start = month.vec[-length(month.vec)],\n",
    "            endt = month.vec[-1],\n",
    "            stringsAsFactors = FALSE\n",
    "        ),\n",
    "        y = data.frame(\n",
    "            admethod,\n",
    "            stringsAsFactors = FALSE\n",
    "        )\n",
    "    ) %>%\n",
    "    slice(\n",
    "        46:54\n",
    "    )\n",
    "    \n",
    "#     return(all.pulls)\n",
    "    \n",
    "    \n",
    "    ##  Run (try) query for each permutation.\n",
    "    pmap(\n",
    "        .l = list(all.pulls$start, all.pulls$end, all.pulls$admethod),\n",
    "        .f = function (start, end, admethod) {\n",
    "            try({\n",
    "                getDF(\n",
    "                    timestart = start,\n",
    "                    timeend = end,\n",
    "                    admethod = admethod,\n",
    "                    write = TRUE\n",
    "                )\n",
    "            })\n",
    "        }\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getBindedDFs = function (write = FALSE) {\n",
    "    \n",
    "    ##  Define files and admethods\n",
    "    data.files = list.files(\"..\\\\data-v2\")\n",
    "    admethod =\n",
    "        c(\n",
    "            'LenderEdge 4',\n",
    "            'Even Financial 4',\n",
    "            'Monevo',\n",
    "            'Quin Street 4',\n",
    "            'LeadGroup',\n",
    "            'LeapTheory 4'\n",
    "        ) %>%\n",
    "        str_to_lower() %>%\n",
    "        str_remove_all('\\\\s')\n",
    "    \n",
    "    ##  Return list, where each element is the data frame for a given partner.\n",
    "    if (write) {\n",
    "        admethod %>% \n",
    "            map( ## 115s\n",
    "                .f = ~ data.files %>%\n",
    "                    as.data.frame(\n",
    "                        stringsAsFactors = FALSE\n",
    "                    ) %>% \n",
    "                    rename(\n",
    "                        file.name = '.'\n",
    "                    ) %>% \n",
    "                    filter(\n",
    "                        file.name %>% str_detect(.x)\n",
    "                    ) %>% \n",
    "                    transmute(\n",
    "                        file.path = paste0(\"..\\\\data-v2\\\\\", file.name)\n",
    "                    ) %>% \n",
    "                    .$file.path %>%\n",
    "                    lapply(\n",
    "                        FUN = function (x) {\n",
    "                            suppressWarnings({suppressMessages({\n",
    "                                read_csv(x)\n",
    "                            })})\n",
    "                        }\n",
    "                    ) %>%\n",
    "                    do.call(\n",
    "                        what = rbind,\n",
    "                        args = .\n",
    "                    ) %>%\n",
    "                    {\n",
    "                        if (write) { ##  redundant, but keeping it in because it's cool\n",
    "                            . %T>% write.csv(\n",
    "                                paste0(\"..\\\\data-v2\\\\\", .x, \".csv\"),\n",
    "                                row.names = FALSE\n",
    "                            )\n",
    "                        } else {\n",
    "                            return(.)\n",
    "                        }\n",
    "                    }()\n",
    "            ) %>% \n",
    "            setNames(\n",
    "                admethod %>% str_remove_all('\\\\d')\n",
    "            )\n",
    "    } else {\n",
    "        admethod %>% \n",
    "            map(\n",
    "                .f = ~ suppressWarnings({suppressMessages({\n",
    "                    read_csv(paste0(\"..\\\\data-v2\\\\\", .x, \".csv\"))\n",
    "                })})\n",
    "            ) %>% \n",
    "            setNames(\n",
    "                admethod %>% str_remove_all('\\\\d')\n",
    "            )\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "appendCutV1 = function (df.list) {\n",
    "    \n",
    "    ##  This function indicates whether the application would be captured by v1's rules.  ##\n",
    "    \n",
    "    #   Defines v1 rules. Returns list where each element is the rule for that admethod   #\n",
    "    getCutsV1 = function () {\n",
    "\n",
    "        list(\n",
    "            lenderedge = expr(\n",
    "                (\n",
    "                  is.na(ccr_score) &\n",
    "                  is.na(ccr_number_of_bank_accounts)\n",
    "#                 ) |\n",
    "#                 (\n",
    "#                   !is.na(ccr_score) & ccr_score < 543 &\n",
    "#                   !is.na(ccr_number_of_bank_accounts) & ccr_number_of_bank_accounts >= 2.5 &\n",
    "#                   !is.na(campaign_id) & campaign_id %in% c('1716','1724','1726','1730','1731','1732','1734','1744','1745') &\n",
    "#                   !is.na(ccr_highest_number_of_days_past_due) & ccr_highest_number_of_days_past_due < 5.5\n",
    "                )\n",
    "            ),\n",
    "            evenfinancial = expr(\n",
    "                is.na(ccr_score) &\n",
    "                is.na(ccr_number_of_bank_accounts)\n",
    "            ),\n",
    "            monevo = expr(\n",
    "                (\n",
    "                    is.na(ccr_score) &\n",
    "                    is.na(ccr_number_of_bank_accounts)\n",
    "#                 ) |\n",
    "#                 (\n",
    "#                     !is.na(ccr_number_of_loans) &ccr_number_of_loans < 0.5 &\n",
    "#                     !is.na(requestedloanamount) & requestedloanamount >= 5150\n",
    "                )\n",
    "            ),\n",
    "            quinstreet = expr(\n",
    "                is.na(ccr_score) &\n",
    "                is.na(ccr_number_of_bank_accounts)\n",
    "            ),\n",
    "            leadgroup = expr(\n",
    "                is.na(ccr_score) &\n",
    "                is.na(ccr_number_of_bank_accounts)\n",
    "            ),\n",
    "            leaptheory = expr(TRUE)\n",
    "        )\n",
    "\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #   For each admethod in df.list, append a column that indicates whether it was a v1 cut.   #\n",
    "    df.list %>% names() %>% \n",
    "        map(\n",
    "            .f = ~ df.list[[.x]] %>% \n",
    "                mutate(\n",
    "                    is.cut.v1 = eval(getCutsV1()[[.x]])\n",
    "                )\n",
    "        ) %>% \n",
    "        setNames(\n",
    "            nm = df.list %>% names()\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getAllDFs()\n",
    "df.list = getBindedDFs() %>% appendCutV1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     14
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##delimited doesn't give what is expected - i think the sorting between .l in pmap and names in .f are off\n",
    "getWaterfall = function () {\n",
    "    \n",
    "    querySnowflake(\n",
    "    \"\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        periscope_de.periscope_views.bizops_application_waterfall\n",
    "    limit 10\n",
    "    \"\n",
    "    )\n",
    "    \n",
    "}\n",
    "attachDelimitedWaterfall = function (waterfall) {\n",
    "\n",
    "    waterfall %>% \n",
    "\n",
    "        ##  I need to make the column names easily referenced as variable, i.e., syntax that wouldn't require ``  ##\n",
    "\n",
    "\n",
    "        ##  1. I remove spaces from colnames.\n",
    "        rename_all(\n",
    "            .funs = ~ .x %>% str_to_lower() %>% str_remove_all('\\\\s')\n",
    "        ) %>% \n",
    "        ##  2. I consolidate duplicate columns\n",
    "        mutate(\n",
    "            `05-nodirectdeposit` = max(`05-nodirectdeposit`, `21-nodirectdeposit`),\n",
    "            `06-bankduration` = max(`06-bankduration`, `15-bankduration`)\n",
    "        ) %>% \n",
    "        select(\n",
    "            -`21-nodirectdeposit`,\n",
    "            -`15-bankduration`\n",
    "        ) %>% \n",
    "        ##  3. I convert character to logical\n",
    "        mutate_at(\n",
    "            .vars = vars(matches('^\\\\d{2}')),\n",
    "            .funs = as.logical\n",
    "        ) %>% \n",
    "        ##  4. I remove numbers and hyphens\n",
    "        rename_all(\n",
    "            .funs = ~ .x %>% \n",
    "                str_replace_all(\n",
    "                    pattern = '\\\\d{2}-',\n",
    "                    replacement = ''\n",
    "                ) %>%\n",
    "                str_remove_all('-')\n",
    "        ) %>% \n",
    "\n",
    "\n",
    "        ##  I need to make a new column that lists the UNCLEANED waterfall name when value is true  ##\n",
    "        ##  Approach:\n",
    "        ##  1. Map over each of the waterfall variables.\n",
    "        ##  2. For each row, determine which variables are true.\n",
    "        ##    - Transform variables into long-wise list.\n",
    "        ##    - Name each list element (which is the T/F value) with the original column name.\n",
    "        ##  3. Create the delimited list. Take the original column name when the value is TRUE.\n",
    "\n",
    "        mutate(\n",
    "\n",
    "            ##  I need to make a new column that lists the UNCLEANED waterfall name when value is true  ##\n",
    "            ##  This part -- https://community.rstudio.com/t/how-to-select-columns-when-using-pmap-inside-of-mutate-for-rowwise-operation/23086/2\n",
    "            ##  Needs to reflect the cleaning above before the mutate.\n",
    "            delimited = pmap(\n",
    "\n",
    "                .l = list(\n",
    "                    ##  parse_exprs creates a list of variables based on the string vector returned\n",
    "                    ##  !!! converts EACH element in the list to an argument passed into function (which is list())\n",
    "                    !!!rlang::parse_exprs(\n",
    "                        waterfall %>% \n",
    "                            rename_all(\n",
    "                                .funs = ~ .x %>% str_to_lower() %>% str_remove_all('\\\\s')\n",
    "                            ) %>% \n",
    "                            mutate(\n",
    "                                `05-nodirectdeposit` = max(`05-nodirectdeposit`, `21-nodirectdeposit`),\n",
    "                                `06-bankduration` = max(`06-bankduration`, `15-bankduration`)\n",
    "                            ) %>% \n",
    "                            select(\n",
    "                                -`21-nodirectdeposit`,\n",
    "                                -`15-bankduration`\n",
    "                            ) %>% \n",
    "                            select_at(\n",
    "                                .vars = vars(matches('^\\\\d{2}'))\n",
    "                            ) %>% \n",
    "                            rename_all(\n",
    "                                .funs = ~ .x %>% \n",
    "                                    str_replace_all(\n",
    "                                        pattern = '\\\\d{2}-',\n",
    "                                        replacement = ''\n",
    "                                    ) %>%\n",
    "                                    str_remove_all('-')\n",
    "                            ) %>% \n",
    "                            colnames() %>% \n",
    "                            sort()\n",
    "                    )\n",
    "                ), \n",
    "\n",
    "                .f = function (...) {\n",
    "\n",
    "\n",
    "                    ##  All the variables passed into above pmap is now a list\n",
    "                    vars = list(...)\n",
    "\n",
    "\n",
    "                    ##  Naming each list element (which is the T/F value) provides a way to link the T/F value to the column name.\n",
    "                    names(vars) = waterfall %>% \n",
    "                        rename_all(\n",
    "                            .funs = ~ .x %>% str_to_lower\n",
    "                        ) %>% \n",
    "                        select_at(\n",
    "                            .vars = vars(matches('^\\\\d{2}'))\n",
    "                        ) %>% \n",
    "                        select(\n",
    "                            -`21-no direct deposit`,\n",
    "                            -`15-bank duration`\n",
    "                        ) %>% \n",
    "                        colnames() %>% \n",
    "                        sort()\n",
    "                    \n",
    "\n",
    "                    ##  More easily converted into a data frame\n",
    "                    data.frame(\n",
    "                        key = vars %>% names(),\n",
    "                        value = vars %>% unlist(),\n",
    "                        stringsAsFactors = FALSE\n",
    "                    ) %>% \n",
    "                    mutate(\n",
    "                        to.delimit = case_when(\n",
    "                            value ~ key,\n",
    "                            TRUE ~ ''\n",
    "                        )\n",
    "                    ) %>% \n",
    "                    ##  Delimit cases that are TRUE\n",
    "                    .$to.delimit %>% \n",
    "                    paste(\n",
    "                        collapse = ' '\n",
    "                    ) %>% \n",
    "                    str_replace_all(\n",
    "                        pattern = '(?<=.)\\\\s',\n",
    "                        replacement = ', '\n",
    "                    ) %>% \n",
    "                    str_trim(\n",
    "                        side = 'both'\n",
    "                    )\n",
    "\n",
    "                }\n",
    "            )\n",
    "        ) %>% \n",
    "        filter(\n",
    "            loanid == 'APP-0003866618'\n",
    "        ) %>%\n",
    "        select(\n",
    "            loanid,\n",
    "            reasongrp,\n",
    "            clarityearlyscreen,\n",
    "            delimited\n",
    "        )\n",
    "    \n",
    "}\n",
    "# waterfall = getWaterfall()\n",
    "# waterfall %>% attachDelimitedWaterfall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getLoanPerformance = function () {\n",
    "    \n",
    "    queryReporting(\n",
    "    \"\n",
    "    select\n",
    "        applicationid as application\n",
    "        , truefpd\n",
    "    from\n",
    "        tableau_reporting.tbl_pd_rate_loan_level\n",
    "    where\n",
    "        appldate >= '2019-10-01'::date\n",
    "    \"\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Across all channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [],
   "source": [
    "cleanColumnValues = function (df) {\n",
    "    \n",
    "    ##  This function converts defined unexpected values to a value that can be better detected by the model.  ##\n",
    "    \n",
    "    ##  Brackets show up in many numeric columns; Want to differentiate from NA.\n",
    "    convertBracketToNeg1 = function (val) {\n",
    "        ifelse(val == '{}', -1, val)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ##  For each admethod-element: run above functions on each column in these DFs. Then clean campaign.\n",
    "    ##  Returns DF of all <chr>.\n",
    "    df %>% \n",
    "        apply(\n",
    "            MARGIN = 2,\n",
    "            FUN = convertBracketToNeg1\n",
    "        ) %>% \n",
    "        as.data.frame(\n",
    "            stringsAsFactors = FALSE\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            ##  Specifies any pattern to the admethod campaign from which to extract the true classifier.\n",
    "            campaign_id = case_when(\n",
    "                admethod == 'Even Financial 4' ~ campaign_id %>% str_remove_all('::.*$'),\n",
    "                admethod == 'LeadGroup' ~ campaign_id %>% map_chr(.f = ~ .x %>% str_match('\\\\-(\\\\d{6})\\\\-') %>% .[,2]),\n",
    "                admethod == 'LeapTheory 4' ~ campaign_id %>% str_remove_all('-.*$'),\n",
    "                admethod %in% c('LenderEdge 4', 'Monevo', 'Quin Street 4') ~ campaign_id\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "expandColumnValues = function (df) {\n",
    "    \n",
    "    ## ccr_worst_payment_rating: try to do analysis on the side; or use as factor in model\n",
    "    df\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "convertColumnTypes = function (df) {\n",
    "    \n",
    "    defineColumnTypes = function () {\n",
    "    \n",
    "        char = c(\n",
    "            'lead_id',\n",
    "            'lead_id_to_visine',\n",
    "            'apiversion',\n",
    "            'admethod',\n",
    "            'reason',\n",
    "            'leadofferid',\n",
    "            'usage_id',\n",
    "            'cached_report_id',\n",
    "            'report_name',\n",
    "            'application_bridge',\n",
    "            'loanid',\n",
    "            'application',\n",
    "            'origination_id',\n",
    "            'adgrp',\n",
    "            'denygrp',\n",
    "            'denial_reason'\n",
    "        )\n",
    "\n",
    "        factor = c(\n",
    "            'campaign_id',\n",
    "            'incometype',\n",
    "            'payrollfrequency',\n",
    "            'payrolltype',\n",
    "            'statecode',\n",
    "            'paycheck_direct_deposit',\n",
    "            'ccr_worst_payment_rating'\n",
    "        )\n",
    "\n",
    "        date = c(\n",
    "            'lead_time',\n",
    "            'lastpayrolldate',\n",
    "            'dateofbirth',\n",
    "            'usage_time',\n",
    "            'report_time',\n",
    "            'work_hiredate',\n",
    "            'appldate'\n",
    "        )\n",
    "        \n",
    "        logical = c(\n",
    "            'srh_online_loan_opened_in_the_last_year', ##also in nums. str -> logical -> num\n",
    "            'srh_online_loan_inquiry_in_the_last_thirty_days', ##also in nums. str -> logical -> num\n",
    "            'is.cut.v1'\n",
    "        )\n",
    "\n",
    "        num = c(\n",
    "            'lead_day',\n",
    "            'accepted',\n",
    "            'code',\n",
    "            'partnerid',\n",
    "            'requested_loan_amount',\n",
    "            'grossmonthlyincome',\n",
    "            'age',\n",
    "            'ofac_score',\n",
    "            'ssn_distinct_first_last_name_count',\n",
    "            'ccr_score',\n",
    "            'ccr_number_of_loans',\n",
    "            'ccr_number_of_bank_accounts',\n",
    "            'ccr_highest_number_of_days_past_due',\n",
    "            'ccr_current_inquiry_cluster_position',\n",
    "            'ccr_days_since_last_loan_charged_off',\n",
    "            'ccr_days_since_inquiry_previously_seen',\n",
    "            'ccr_number_of_employers_last_six_months',\n",
    "            'srh_loans_in_collections',\n",
    "            'srh_spml_average_rollovers',\n",
    "            'srh_amount_loans_charged_off',\n",
    "            'srh_online_loan_opened_in_the_last_year',\n",
    "            'srh_online_loan_inquiry_in_the_last_thirty_days',\n",
    "            'ticrh_ninety_days_ago',\n",
    "            'ticrh_twentyfour_hours_ago',\n",
    "            'newentered',\n",
    "            'bizrulespassed',\n",
    "            'qualified',\n",
    "            'bankverified',\n",
    "            'passscorecardratecard',\n",
    "            'contractsigned',\n",
    "            'cs_decisioned',\n",
    "            'funded'\n",
    "        )\n",
    "\n",
    "        list(\n",
    "            char = char,\n",
    "            factor = factor,\n",
    "            date = date,\n",
    "            num = num,\n",
    "            logical = logical\n",
    "        )\n",
    "\n",
    "    }\n",
    "    \n",
    "    df %>% \n",
    "        mutate_at(\n",
    "            .vars = defineColumnTypes()$char,\n",
    "            .funs = as.character\n",
    "        ) %>% \n",
    "        mutate_at(\n",
    "            .vars = defineColumnTypes()$factor,\n",
    "            .funs = ~ .x %>% str_to_upper() %>% as.factor\n",
    "        ) %>% \n",
    "        mutate_at(\n",
    "            .vars = defineColumnTypes()$date,\n",
    "            .funs = as.Date\n",
    "        ) %>% \n",
    "        mutate_at(\n",
    "            .vars = defineColumnTypes()$logical,\n",
    "            .funs = ~ .x %>% str_trim(side = 'both') %>% as.logical\n",
    "        ) %>%\n",
    "        mutate_at(\n",
    "            .vars = defineColumnTypes()$num,\n",
    "            .funs = as.numeric\n",
    "        )\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "imputeMissingValues = function (df) {\n",
    "    \n",
    "    df %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.numeric,\n",
    "            .funs = replace_na,\n",
    "            replace = -10000\n",
    "        ) %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.character,\n",
    "            .funs = replace_na,\n",
    "            replace = '<blank>'\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "filterModelRows = function (df, denominator.quo, campaign_id_keep = NA) {\n",
    "    \n",
    "    df %>% \n",
    "        filter(\n",
    "            !is.cut.v1 &\n",
    "            !!denominator.quo == 1\n",
    "        ) %>% \n",
    "        ##  Filter by campaign if specified\n",
    "        {\n",
    "            if (!is.na(campaign_id_keep)) {\n",
    "\n",
    "                . %>% filter(campaign_id %in% campaign_id_keep)\n",
    "\n",
    "            } else {\n",
    "\n",
    "                return(.)\n",
    "            }\n",
    "        }()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "filterModelColumns = function (df, numerator.quo) {\n",
    "    \n",
    "    columnsToKeep = function () {\n",
    "        c(\n",
    "            'campaign_id',\n",
    "            'incometype',\n",
    "            'payrollfrequency',\n",
    "            'payrolltype',\n",
    "            'paycheck_direct_deposit',\n",
    "            'ccr_worst_payment_rating',\n",
    "            'lead_day',\n",
    "            'requested_loan_amount',\n",
    "            'grossmonthlyincome',\n",
    "            'age',\n",
    "            'ofac_score',\n",
    "            'ssn_distinct_first_last_name_count',\n",
    "            'ccr_score',\n",
    "            'ccr_number_of_loans',\n",
    "            'ccr_number_of_bank_accounts',\n",
    "            'ccr_highest_number_of_days_past_due',\n",
    "            'ccr_current_inquiry_cluster_position',\n",
    "            'ccr_days_since_last_loan_charged_off',\n",
    "            'ccr_days_since_inquiry_previously_seen',\n",
    "            'ccr_number_of_employers_last_six_months',\n",
    "            'srh_loans_in_collections',\n",
    "            'srh_spml_average_rollovers',\n",
    "            'srh_amount_loans_charged_off',\n",
    "            'srh_online_loan_opened_in_the_last_year',\n",
    "            'srh_online_loan_inquiry_in_the_last_thirty_days',\n",
    "            'ticrh_ninety_days_ago',\n",
    "            'ticrh_twentyfour_hours_ago',\n",
    "            quo_name(numerator.quo)\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    df %>% \n",
    "        select_at(\n",
    "            .vars = columnsToKeep()\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "balanceResponseWeight = function (df, numerator.quo) {\n",
    "    \n",
    "    ##  Will return error in nrow(x) == 0\n",
    "    if (nrow(df) > 0) {\n",
    "\n",
    "        positive.response = df %>% filter(!!numerator.quo == 1)\n",
    "        negative.response = df %>% filter(!!numerator.quo == 0)\n",
    "\n",
    "        positive.count = positive.response %>% nrow()\n",
    "        negative.count = negative.response %>% nrow()\n",
    "\n",
    "\n",
    "        ##  How many times do we need each response level?\n",
    "        ##  Need to account for case where a response level has 0 obs.\n",
    "        positive.n = max(\n",
    "            ifelse(\n",
    "                is.infinite(floor(negative.count / positive.count)),\n",
    "                0,\n",
    "                floor(negative.count / positive.count)\n",
    "            ),\n",
    "            1\n",
    "        )\n",
    "        negative.n = max(\n",
    "            ifelse(\n",
    "                is.infinite(floor(positive.count / negative.count)),\n",
    "                0,\n",
    "                floor(positive.count / negative.count)\n",
    "            ),\n",
    "            1\n",
    "        )\n",
    "\n",
    "        rbind(  ##  Returns DF\n",
    "            do.call(  ##  Returns DF\n",
    "                what = rbind,\n",
    "                args = replicate(  ##  Returns list of length n of DFs\n",
    "                    n = positive.n,\n",
    "                    expr = {rbind(data.frame(), positive.response)},\n",
    "                    simplify = FALSE\n",
    "                )\n",
    "            ),\n",
    "            do.call(  ##  Returns DF\n",
    "                what = rbind,\n",
    "                args = replicate(  ##  Returns list of length n of DFs\n",
    "                    n = negative.n,\n",
    "                    expr = {rbind(data.frame(), negative.response)},\n",
    "                    simplify = FALSE\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    } else {\n",
    "        df\n",
    "    }   \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed = df.list %>% \n",
    "#     .$lenderedge %>%\n",
    "    .$evenfinancial %>%\n",
    "#     head(\n",
    "#         50\n",
    "#     ) %>% \n",
    "    cleanColumnValues() %>% \n",
    "    expandColumnValues() %>% \n",
    "    convertColumnTypes() %>% \n",
    "    imputeMissingValues() %>% \n",
    "    filterModelRows(\n",
    "        denominator.quo = quo(newentered),\n",
    "        campaign_id_keep = NA\n",
    "    ) %>%\n",
    "    filterModelColumns(\n",
    "        numerator.quo = quo(bankverified)\n",
    "    ) %>% \n",
    "    balanceResponseWeight(\n",
    "        numerator.quo = quo(bankverified)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed %>% str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "convertDataTypes = function (raw.df) {\n",
    "    \n",
    "    data.type.list = list(\n",
    "        booleans = c(\n",
    "            'paycheck_direct_deposit',\n",
    "            'srh_online_loan_opened_in_the_last_year',\n",
    "            'srh_online_loan_inquiry_in_the_last_thirty_days'\n",
    "        ),\n",
    "        numerics = c(\n",
    "            'ofac_score',\n",
    "            'ssn_distinct_first_last_name_count',\n",
    "            'ccr_score',\n",
    "            'ccr_number_of_loans',\n",
    "            'ccr_number_of_bank_accounts',\n",
    "            'ccr_highest_number_of_days_past_due',\n",
    "            'ccr_current_inquiry_cluster_position',\n",
    "            'ccr_days_since_last_loan_charged_off',\n",
    "            'ccr_days_since_inquiry_previously_seen',\n",
    "            'ccr_number_of_employers_last_six_months',\n",
    "            'srh_loans_in_collections',\n",
    "            'srh_spml_average_rollovers',\n",
    "            'srh_amount_loans_charged_off',\n",
    "            'ticrh_ninety_days_ago',\n",
    "            'ticrh_twentyfour_hours_ago'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    raw.df %>% \n",
    "        mutate_at(\n",
    "            .vars = data.type.list$booleans,\n",
    "            .funs = as.logical\n",
    "        ) %>%  \n",
    "        mutate_at(\n",
    "            .vars = data.type.list$numerics,\n",
    "            .funs = as.numeric\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "processColumns = function (converted.df) {\n",
    "\n",
    "    converted.df %>% \n",
    "        mutate(\n",
    "            ccr_worst_payment_rating_null = is.na(ccr_worst_payment_rating),\n",
    "            ccr_worst_payment_rating_plus = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '+',\n",
    "            ccr_worst_payment_rating_zero = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '0',\n",
    "            ccr_worst_payment_rating_hash = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '#',\n",
    "            ccr_worst_payment_rating_else = !(\n",
    "                ccr_worst_payment_rating_plus |\n",
    "                ccr_worst_payment_rating_zero |\n",
    "                ccr_worst_payment_rating_hash |\n",
    "                ccr_worst_payment_rating_null\n",
    "            ),\n",
    "\n",
    "            ccr_has_previous_loan_charged_off = case_when(\n",
    "                is.na(ccr_days_since_last_loan_charged_off) ~ FALSE,\n",
    "                TRUE ~ TRUE\n",
    "            ),\n",
    "            \n",
    "            payrolltype = payrolltype %>% replace_na('Missing'),\n",
    "            campaign_id = campaign_id %>% map(~ .x %>% str_match_all(\"\\\\\\\"(.*)\\\\\\\"\") %>% .[[1]] %>% .[,2]) %>% as.character()\n",
    "            \n",
    "        ) %>% \n",
    "        select(\n",
    "            -ccr_worst_payment_rating,\n",
    "            -ccr_days_since_last_loan_charged_off\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "imputeMissingValues = function (processed.df) {\n",
    "    \n",
    "\n",
    "    impute.10000 = c(\n",
    "        'ccr_days_since_inquiry_previously_seen',\n",
    "        'ccr_number_of_loans',\n",
    "        'ccr_number_of_bank_accounts',\n",
    "        'ccr_highest_number_of_days_past_due',\n",
    "        'ccr_current_inquiry_cluster_position',\n",
    "        'ccr_number_of_employers_last_six_months',\n",
    "        'ccr_score'\n",
    "    )\n",
    "    \n",
    "    processed.df %>%\n",
    "        mutate_at(\n",
    "            .vars = impute.10000,\n",
    "            .funs = ~ .x %>%\n",
    "                replace_na(\n",
    "                    replace = 10000\n",
    "                )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "standardizeValues = function (imputed.df) {\n",
    "    return(imputed.df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "keepModelFeatures = function (standardized.df) {\n",
    "    \n",
    "    standardized.df %>% \n",
    "        select(\n",
    "            -lead_id,\n",
    "            -leadofferid,\n",
    "            -lead_time,\n",
    "            -partnerid,\n",
    "            -accepted,\n",
    "            -reason,\n",
    "            -code,\n",
    "            -campaign_id,\n",
    "            -bankname,\n",
    "            -abaroutingnumber,\n",
    "            -accountnumber,\n",
    "            -payrollfrequency,\n",
    "            -payrolltype,\n",
    "            -work_hiredate,\n",
    "            -lastpayrolldate,\n",
    "            -dateofbirth,\n",
    "            -report_time,\n",
    "            -has_clarity,\n",
    "            -report_requested,\n",
    "            -report_received,\n",
    "            -report_time,\n",
    "            -appldate,\n",
    "#             -newentered,\n",
    "            -bizrulespassed,\n",
    "#             -qualified,\n",
    "            -bankverified,\n",
    "            -passscorecardratecard,\n",
    "            -contractsigned,\n",
    "            -cs_decisioned,\n",
    "            -offer_interestrate,\n",
    "            -offer_monthlypayment,\n",
    "            -offer_amount,\n",
    "            -application\n",
    "        ) %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.character,\n",
    "            .funs = as.factor\n",
    "        ) %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.logical,\n",
    "            .funs = as.factor\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "removeMissingObservations = function (feature.df) {\n",
    "    \n",
    "    feature.df %>% \n",
    "#         mutate(\n",
    "        filter(\n",
    "            apply(\n",
    "                X = feature.df,\n",
    "                FUN = function (x) { x %>% is.na() %>% sum() },\n",
    "                MARGIN = 1\n",
    "            ) == 0\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getColPercNA = function (df) {\n",
    "\n",
    "    df %>% \n",
    "        apply(\n",
    "            FUN = function (x) {\n",
    "                x %>% is.na() %>% mean()\n",
    "            },\n",
    "            MARGIN = 2\n",
    "        ) %>% \n",
    "        as.data.frame() %>% \n",
    "        select(\n",
    "            perc.na = '.'\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            var = 'column'\n",
    "        ) %>% \n",
    "        arrange(\n",
    "            perc.na %>% desc()\n",
    "        )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeTraining = function (admethod = 'CreditKarma4') {\n",
    "    \n",
    "    df.feb =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2020-02-01',\n",
    "            timeend = '2020-02-23',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "    df.jan =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2020-01-01',\n",
    "            timeend = '2020-02-01',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "    df.dec =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2019-12-01',\n",
    "            timeend = '2020-01-01',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "\n",
    "    df = do.call(\n",
    "        rbind,\n",
    "        list(df.feb, df.jan, df.dec)\n",
    "    )\n",
    "    \n",
    "    df %>% write.csv(\n",
    "        paste0(\n",
    "            \"..\\\\data\\\\df-\",\n",
    "            admethod %>% getShortenedAdmethodName(),\n",
    "            \".csv\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readTraining = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeTraining()\n",
    "    \n",
    "    df.feb =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2020-02-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "\n",
    "    df.jan =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2020-01-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "\n",
    "    df.dec =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2019-12-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "    \n",
    "    df = do.call(\n",
    "        rbind,\n",
    "        list(df.feb, df.jan, df.dec)\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     df = do.call(\n",
    "#         what = rbind,\n",
    "#         args = lapply(\n",
    "#             X = c(\n",
    "#                 \"..\\\\data\\\\df-lenderedge-2020-01-01.csv\",\n",
    "#                 \"..\\\\data\\\\df-lenderedge-2020-02-01.csv\"\n",
    "#             ),\n",
    "#             FUN = function (x) {\n",
    "#                 suppressWarnings({suppressMessages({\n",
    "#                     read_csv(x)\n",
    "#                 })})\n",
    "#             }\n",
    "#         )\n",
    "#     ) %>% select(-X1)\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.train = readTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeTest = function (admethod = 'CreditKarma4', timestart = '2020-03-01', timeend = '2020-03-08') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-test.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readTest = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeTest()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-01.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.test = readTest(write = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate = function (admethod = 'CreditKarma4', timestart = '2020-02-23', timeend = '2020-03-01') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-02-23.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate = readValidate(write = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Additional Validates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate2 = function (admethod = 'CreditKarma4', timestart = '2020-03-08', timeend = '2020-03-15') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate2.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate2 = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate2()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-08.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate2 = readValidate2(write = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate3 = function (admethod = 'CreditKarma4', timestart = '2020-03-15', timeend = '2020-03-22') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate3.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate3 = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate3()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-15.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate3 = readValidate3(write = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate4 = function (admethod = 'CreditKarma4', timestart = '2020-03-22', timeend = '2020-03-29') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate4.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate4 = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate4()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-22.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate4 = readValidate4(write = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate5 = function (admethod = 'CreditKarma4', timestart = '2020-03-29', timeend = '2020-04-05') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate5.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate5 = function (admethod = 'CreditKarma4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate5()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-29.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate5 = readValidate5(write = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "upsampleImbalancedClassInTraining = function (df.train, upsample.multiple = 47, quietly = FALSE) {\n",
    "\n",
    "    ###  Upsample Minority Class (Funded == 1)  ###\n",
    "    if (!quietly) {\n",
    "        cat(\"Pre Upsample:\\n\")\n",
    "        print(df.train %>% group_by(funded) %>% summarize(n()))\n",
    "        cat('\\n')\n",
    "    }\n",
    "\n",
    "    train.funded = df.train %>% filter(funded == 'TRUE')\n",
    "    funded.rep.df = do.call(\n",
    "        rbind,\n",
    "        replicate(\n",
    "            n = upsample.multiple,\n",
    "            expr = {\n",
    "                rbind(data.frame(), train.funded)\n",
    "            },\n",
    "            simplify = FALSE\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    train.bal = rbind(\n",
    "        df.train,\n",
    "        funded.rep.df\n",
    "    )\n",
    "    \n",
    "    if (!quietly) {\n",
    "        cat(\"\\nPost Upsample:\\n\")\n",
    "        print(train.bal %>% group_by(funded) %>% summarize(n()))\n",
    "        cat('\\n')\n",
    "    }\n",
    "    \n",
    "    return(train.bal)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "removeNewClassesInGeneralization = function (df.generalize, df.train, generalize.name = NA) {\n",
    "    \n",
    "    df.similar = df.generalize %>%\n",
    "        filter(\n",
    "            incometype %in% (df.train$incometype %>% unique()) &\n",
    "#             payrolltype %in% (df.train$payrolltype %>% unique()) &\n",
    "            statecode %in% (df.train$statecode %>% unique()) &\n",
    "#             campaign_id %in% (df.train$campaign_id %>% unique()) &\n",
    "            paycheck_direct_deposit %in% (df.train$paycheck_direct_deposit %>% unique()) &\n",
    "            srh_online_loan_opened_in_the_last_year %in% (df.train$srh_online_loan_opened_in_the_last_year %>% unique()) &\n",
    "            srh_online_loan_inquiry_in_the_last_thirty_days %in% (df.train$srh_online_loan_inquiry_in_the_last_thirty_days %>% unique()) &\n",
    "            ccr_worst_payment_rating_null %in% (df.train$ccr_worst_payment_rating_null %>% unique()) &\n",
    "            ccr_worst_payment_rating_plus %in% (df.train$ccr_worst_payment_rating_plus %>% unique()) &\n",
    "            ccr_worst_payment_rating_zero %in% (df.train$ccr_worst_payment_rating_zero %>% unique()) &\n",
    "            ccr_worst_payment_rating_hash %in% (df.train$ccr_worst_payment_rating_hash %>% unique()) &\n",
    "            ccr_worst_payment_rating_else %in% (df.train$ccr_worst_payment_rating_else %>% unique()) &\n",
    "            ccr_has_previous_loan_charged_off %in% (df.train$ccr_has_previous_loan_charged_off %>% unique())\n",
    "        )\n",
    "    \n",
    "    print(\n",
    "        paste0(\n",
    "            nrow(df.generalize) - nrow(df.similar),\n",
    "            ifelse(\n",
    "                is.na(generalize.name),\n",
    "                \" rows removed.\",\n",
    "                paste0(\" rows removed from \", generalize.name, \".\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    return(df.similar)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "processAll = function (df.train, df.test, df.validate, df.validate2) {    \n",
    "    \n",
    "    list(\n",
    "        train = df.train %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        test = df.test %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"test set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        validate = df.validate %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"validation set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        validate2 = df.validate2 %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"validation2 set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        train.bal = df.train %>%\n",
    "            upsampleImbalancedClassInTraining(\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            )\n",
    "    )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split = processAll(\n",
    "    df.train,\n",
    "    df.test,\n",
    "    df.validate,\n",
    "    df.validate2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split$train.bal %>% str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getEvaluation = function (predict.object) {\n",
    "\n",
    "    detailed = predict.object %>% \n",
    "        as.data.frame(\n",
    "            stringsAsFactors = FALSE\n",
    "        ) %>% \n",
    "        group_by(\n",
    "            truth,\n",
    "            response\n",
    "        ) %>% \n",
    "        summarize(\n",
    "            n = n()\n",
    "        ) %>%\n",
    "        ungroup()\n",
    "    \n",
    "    prior = detailed %>% filter(truth == TRUE) %>% .$n %>% sum() /\n",
    "            detailed %>% .$n %>% sum()\n",
    "    \n",
    "    accuracy = detailed %>% filter(truth == response) %>% .$n %>% sum() /\n",
    "            detailed %>% .$n %>% sum()                              ##TP,TN\n",
    "    \n",
    "    recall = detailed %>% filter(truth == TRUE & response == TRUE) %>% .$n %>% sum()/\n",
    "            detailed %>% filter(truth == TRUE) %>% .$n %>% sum()    ##FP\n",
    "    \n",
    "    precision = detailed %>% filter(truth == TRUE & response == TRUE) %>% .$n %>% sum()/\n",
    "            detailed %>% filter(response == TRUE) %>% .$n %>% sum() ##FN\n",
    "    \n",
    "    \n",
    "    metrics = data.frame(\n",
    "        metric = c('prior', 'accuracy', 'recall', 'precision'),\n",
    "        value = c(prior, accuracy, recall, precision),\n",
    "        stringsAsFactors = FALSE\n",
    "    )\n",
    " \n",
    "    list(\n",
    "        detailed = detailed,\n",
    "        metrics = metrics\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getDecisionTree = function (data.split, evaluate = TRUE, xval = 0, minsplit = 1000, minbucket = 1000, cp = 0.001) {\n",
    " \n",
    "\n",
    "    ####  Setup  ####\n",
    "\n",
    "    library(rattle)\n",
    "    # library(rpart)\n",
    "    # suppressWarnings({\n",
    "    #     listLearners() %>%\n",
    "    #         filter(\n",
    "    #             type == 'classif' &\n",
    "    #             name %>% str_detect('[Tt]ree')\n",
    "    #         )\n",
    "    # })\n",
    "    # getParamSet('classif.rpart')\n",
    "\n",
    "    # loss.matrix = matrix(\n",
    "    #     c(0,1,1.6,0),\n",
    "    #     byrow = TRUE,\n",
    "    #     nrow = 2\n",
    "    # )\n",
    "\n",
    "    rpart.task = makeClassifTask(\n",
    "        id = 'rpart.task',\n",
    "        data = data.split$train.bal %>%\n",
    "            select(\n",
    "                -newentered,\n",
    "                -qualified,\n",
    "                -funded_amount,\n",
    "                -type_formula,\n",
    "                -truefpd\n",
    "            ) %>% \n",
    "            select(\n",
    "                ccr_score,\n",
    "                grossmonthlyincome,\n",
    "#                 age,\n",
    "                lead_day,\n",
    "                ccr_days_since_inquiry_previously_seen,\n",
    "#                 requestedloanamount,\n",
    "#                 ccr_number_of_bank_accounts,\n",
    "                ofac_score,\n",
    "                funded\n",
    "            ),\n",
    "        target = 'funded',\n",
    "        positive = 'TRUE'\n",
    "    )\n",
    "\n",
    "    rpart.learner = makeLearner(\n",
    "        cl = 'classif.rpart',\n",
    "        id = 'rpart.learner',\n",
    "        xval = xval,                  ##  Number of Cross Validations\n",
    "        minsplit = minsplit,             ##  Number of Obs in Node for Split to be Attempted\n",
    "        minbucket = minbucket,             ##  Minimum number of observations in Leaf Node\n",
    "        cp = cp                ##  Minimum information gain for split to execute.\n",
    "    #     loss = loss.matrix\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Resampling  ####\n",
    "\n",
    "    # rpart.resample = makeResampleDesc('CV', iters = 5, stratify = TRUE)\n",
    "\n",
    "    # rpart.cv = resample(\n",
    "    #     learner = rpart.learner,\n",
    "    #     task = rpart.task,\n",
    "    #     resampling = rpart.resample,\n",
    "    #     measures = list(acc, mmce, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # # rpart.cv %>% .$measures.test\n",
    "    # # rpart.cv %>% .$aggr %>% as.data.frame()\n",
    "\n",
    "\n",
    "\n",
    "    ####  Hypertuning  ####\n",
    "\n",
    "    # rpart.params = makeParamSet(\n",
    "    #     makeIntegerParam('minsplit', lower = 10, upper = 50),\n",
    "    #     makeIntegerParam('minbucket', lower = 5, upper = 50),\n",
    "    #     makeNumericParam('cp', lower = 0.0001, upper = 0.2)\n",
    "    # )\n",
    "\n",
    "    # rpart.search = makeTuneControlGrid()\n",
    "\n",
    "    # rpart.tune = tuneParams(\n",
    "    #     learner = rpart.learner,\n",
    "    #     task = rpart.task,\n",
    "    #     resampling = rpart.resample,\n",
    "    #     par.set = rpart.params,\n",
    "    #     control = rpart.search,\n",
    "    #     measures = list(mmce, acc, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # setHyperPars(\n",
    "    #     learner = rpart.learner,\n",
    "    #     par.vals = rpart.tune$x\n",
    "    # ) \n",
    "\n",
    "\n",
    "\n",
    "    ####  Training  ####\n",
    "\n",
    "    rpart.model = train(\n",
    "        learner = rpart.learner,\n",
    "        task = rpart.task\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Evaluation  ####\n",
    "\n",
    "#     rpart.predict = predict(\n",
    "#         object = rpart.model,\n",
    "#         newdata = data.split$test %>% select(-newentered, -qualified)\n",
    "#     )\n",
    "\n",
    "#     rpart.validate = predict(\n",
    "#         object = rpart.model,\n",
    "#         newdata = data.split$validate %>% select(-newentered, -qualified)\n",
    "#     )\n",
    "\n",
    "#     test.eval = rpart.predict %>% getEvaluation()\n",
    "#     validate.eval = rpart.validate %>% getEvaluation()\n",
    "\n",
    "#     if (evaluate) {\n",
    "#         list(\n",
    "#             test.eval = test.eval,\n",
    "#             validate.eval = validate.eval\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "\n",
    "#     rules = rpart.model$learner.model\n",
    "#     rules.df = rpart.plot::rpart.rules(rpart.model$learner.model)\n",
    "# #     rules.tree = rpart.plot::rpart.plot(rpart.model$learner.model, type = 4)\n",
    "# #     fancyRpartPlot(rpart.model$learner.model)\n",
    "\n",
    "\n",
    "\n",
    "    ####  Outputs  ####\n",
    "    \n",
    "    ##    Tree    ##\n",
    "    pdf(\n",
    "        tf <- tempfile(\n",
    "            fileext = \".pdf\"\n",
    "        )\n",
    "    )\n",
    "    fancyRpartPlot(\n",
    "        rpart.model$learner.model\n",
    "    )\n",
    "    dev.off()\n",
    "    cat(tf)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings({suppressMessages({\n",
    "    data.split %>% getDecisionTree(evaluate = FALSE)\n",
    "})})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getDecisionTreeProposal = function (data.split, nodes.to.exclude.logic.expr, loantype = 'NEW') {    \n",
    "\n",
    "    \n",
    "    ####  Evaluation  ####\n",
    "    evaluatePerformance = function (data.split, stage, loantype.inner = loantype) {\n",
    "        \n",
    "        calculateChangeSize = function (metric.string, observed.metrics = observed, proposed.metrics = proposed) {\n",
    "            \n",
    "            (\n",
    "                100 *\n",
    "                ( proposed.metrics[[metric.string]] - observed.metrics[[metric.string]] ) /\n",
    "                observed.metrics[[metric.string]]\n",
    "            ) %>%\n",
    "            round(2) %>% \n",
    "            paste0('%')\n",
    "            \n",
    "        }\n",
    "        calculateChangeConversion = function (metric.string, observed.metrics = observed, proposed.metrics = proposed) {\n",
    "            \n",
    "            paste0(\n",
    "                ifelse(\n",
    "                    proposed.metrics[[metric.string]] - observed.metrics[[metric.string]] >= 0,\n",
    "                    '+',\n",
    "                    ''\n",
    "                ),\n",
    "                round(\n",
    "                    10000 * (proposed.metrics[[metric.string]] - observed.metrics[[metric.string]]),\n",
    "                    0\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        }\n",
    "        \n",
    "        observed = data.split[[stage]] %>%\n",
    "            filter(\n",
    "                parse(\n",
    "                    text = if_else(\n",
    "                        !is.na(loantype.inner),\n",
    "                        'str_to_upper(type_formula) == str_to_upper(loantype.inner) | is.na(type_formula)',\n",
    "                        'TRUE'\n",
    "                    )\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% \n",
    "            summarize(\n",
    "                accept.size = n(),\n",
    "                app.size = sum(newentered == 'TRUE'),\n",
    "                qual.size = sum(qualified == 'TRUE'),\n",
    "                funded.size = sum(funded == 'TRUE'),\n",
    "                dollar.size = sum(\n",
    "                    (funded == 'TRUE') *\n",
    "                    funded_amount,\n",
    "                    na.rm = TRUE\n",
    "                ),\n",
    "                \n",
    "                apply.rate = app.size/accept.size,\n",
    "                qr = qual.size/app.size,\n",
    "                fr = funded.size/qual.size,\n",
    "                app.to.fund = funded.size/app.size,\n",
    "                accept.to.fund = funded.size/accept.size,\n",
    "                \n",
    "                fpd.mature = sum(funded == 'TRUE' & !is.na(truefpd)) / funded.size,\n",
    "                fpd = sum(funded == 'TRUE' & !is.na(truefpd) & truefpd == 1) / sum(funded == 'TRUE' & !is.na(truefpd))\n",
    "            )\n",
    "\n",
    "        proposed = data.split[[stage]] %>%\n",
    "            filter(\n",
    "                !eval(nodes.to.exclude.logic.expr) &\n",
    "                parse(\n",
    "                    text = if_else(\n",
    "                        !is.na(loantype.inner),\n",
    "                        'str_to_upper(type_formula) == str_to_upper(loantype.inner) | is.na(type_formula)',\n",
    "                        'TRUE'\n",
    "                    )\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% \n",
    "            summarize(\n",
    "                accept.size = n(),\n",
    "                app.size = sum(newentered == 'TRUE'),\n",
    "                qual.size = sum(qualified == 'TRUE'),\n",
    "                funded.size = sum(funded == 'TRUE'),\n",
    "                dollar.size = sum(\n",
    "                    (funded == 'TRUE') *\n",
    "                    funded_amount,\n",
    "                    na.rm = TRUE\n",
    "                ),\n",
    "                \n",
    "                apply.rate = app.size/accept.size,\n",
    "                qr = qual.size/app.size,\n",
    "                fr = funded.size/qual.size,\n",
    "                app.to.fund = funded.size/app.size,\n",
    "                accept.to.fund = funded.size/accept.size,\n",
    "                \n",
    "                fpd.mature = sum(funded == 'TRUE' & !is.na(truefpd)) / funded.size,\n",
    "                fpd = sum(funded == 'TRUE' & !is.na(truefpd) & truefpd == 1) / sum(funded == 'TRUE' & !is.na(truefpd))\n",
    "            )\n",
    "\n",
    "        change = data.frame(\n",
    "            'Size__' = '',\n",
    "            accepted = 'accept.size' %>% calculateChangeSize(),\n",
    "            app = 'app.size' %>% calculateChangeSize(),\n",
    "            qualified = 'qual.size' %>% calculateChangeSize(),\n",
    "            funded = 'funded.size' %>% calculateChangeSize(),\n",
    "            funded.dollar = 'dollar.size' %>% calculateChangeSize(),\n",
    "            \n",
    "            'Rates__' = '',\n",
    "            apply.rate = 'apply.rate' %>% calculateChangeConversion(),\n",
    "            qr = 'qr' %>% calculateChangeConversion(),\n",
    "            fr = 'fr' %>% calculateChangeConversion(),\n",
    "            app.to.fund = 'app.to.fund' %>% calculateChangeConversion(),\n",
    "            accept.to.fund = 'accept.to.fund' %>% calculateChangeConversion(),\n",
    "            \n",
    "            fpd.mature = paste0(round(100*observed$fpd.mature, 2), '%'),\n",
    "            fpd = 'fpd' %>% calculateChangeConversion(),\n",
    "            \n",
    "            stringsAsFactors = FALSE\n",
    "        )\n",
    "        \n",
    "        list(\n",
    "#             observed = observed,\n",
    "#             proposed = proposed,\n",
    "            change = change\n",
    "        )\n",
    "        \n",
    "    }\n",
    "    \n",
    "    list(\n",
    "#         data.split %>% evaluatePerformance('train.bal'),\n",
    "        data.split %>% evaluatePerformance('train'),\n",
    "        data.split %>% evaluatePerformance('test'),\n",
    "        data.split %>% evaluatePerformance('validate'),\n",
    "        data.split %>% evaluatePerformance('validate2')\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "exclude.logic = expr(\n",
    "#     (\n",
    "#         is.na(ccr_score) &\n",
    "#         is.na(ccr_number_of_bank_accounts)\n",
    "#     ) |\n",
    "#     (\n",
    "#         requestedloanamount > 3000 &\n",
    "#         ccr_number_of_bank_accounts == 0\n",
    "#     ) |\n",
    "    (\n",
    "        ccr_worst_payment_rating_null == 'TRUE' &\n",
    "        incometype == 'OtherTaxableIncome'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings({suppressMessages({\n",
    "    data.split %>% getDecisionTreeProposal(exclude.logic)\n",
    "})})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Exclusion Nodes Generalization - Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "plotTimeSeries = function (admethod, exclude.logic.expr) {\n",
    "\n",
    "    df.ts = do.call(\n",
    "        what = rbind,\n",
    "        args = lapply(\n",
    "            X = c(\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2019-12-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-01-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-02-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-02-23.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-03-01.csv\")\n",
    "            ),\n",
    "            FUN = function (x) {\n",
    "                suppressWarnings({suppressMessages({read_csv(x)})})\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ###  Mix  ###\n",
    "    mix.plot = df.ts %>%\n",
    "        group_by(\n",
    "            lead_date = lead_time %>% as.Date()\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            day.total = n()\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        group_by(\n",
    "            lead_date,\n",
    "            exclude = eval(exclude.logic.expr)\n",
    "        ) %>% \n",
    "        summarize(\n",
    "            p = n()/mean(day.total)\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        ggplot(\n",
    "            mapping = aes(\n",
    "                x = lead_date,\n",
    "                y = p,\n",
    "                color = exclude\n",
    "            )\n",
    "        ) +\n",
    "        geom_line() +\n",
    "        geom_point() +\n",
    "        scale_y_continuous(\n",
    "            labels = scales::percent\n",
    "        ) +\n",
    "        labs(\n",
    "            title = \"Mix of Exclude\"\n",
    "        ) +\n",
    "        theme_bw()\n",
    "\n",
    "    ###  Conversion - FR  ###\n",
    "    conversion.plot = df.ts %>%\n",
    "        group_by(\n",
    "            lead_date = lead_time %>% as.Date(),\n",
    "            exclude = eval(exclude.logic.expr)\n",
    "        ) %>% \n",
    "        summarize(\n",
    "    #         conversion = sum(funded)/sum(qualified)\n",
    "    #         conversion = sum(qualified)/sum(newentered)\n",
    "    #         conversion = sum(newentered)/n()\n",
    "    #         conversion = sum(funded)/sum(newentered)\n",
    "            conversion = sum(funded)/n()\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        ggplot(\n",
    "            mapping = aes(\n",
    "                x = lead_date,\n",
    "                y = conversion,\n",
    "                color = exclude\n",
    "            )\n",
    "        ) +\n",
    "        geom_line() +\n",
    "        geom_point() +\n",
    "        scale_y_continuous(\n",
    "            labels = scales::percent\n",
    "        ) +\n",
    "        labs(\n",
    "            title = \"Conversion of Exclude\"\n",
    "        ) +\n",
    "        theme_bw()\n",
    "\n",
    "    \n",
    "    list(\n",
    "        mix.plot,\n",
    "        conversion.plot\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CreditKarma4' %>% plotTimeSeries(exclude.logic.expr = exclude.logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getRemoveNALogic = function (data.split) {\n",
    "    \n",
    "    data.split$train.bal %>% \n",
    "        select(\n",
    "            -truefpd,\n",
    "            -type_formula,\n",
    "            -funded_amount\n",
    "        ) %>% \n",
    "        apply(\n",
    "            FUN = function (x) {x %>% is.na() %>% mean()},\n",
    "            MARGIN = 2\n",
    "        ) %>% \n",
    "        as.data.frame(\n",
    "        ) %>%\n",
    "        select(\n",
    "            perc = '.'\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            'field'\n",
    "        ) %>% \n",
    "        filter(\n",
    "            perc > 0\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            expression = field %>% \n",
    "                map(\n",
    "                    .f = ~ paste0(\n",
    "                        '!is.na(',\n",
    "                        .x,\n",
    "                        ')'\n",
    "                    )\n",
    "                ) %>% as.character()\n",
    "        ) %>% \n",
    "        .$expression %>% \n",
    "        paste0(\n",
    "            collapse = ' & '\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "getRandomForest = function (\n",
    "    data.split,\n",
    "    evaluate = FALSE,\n",
    "    ntree = 24,\n",
    "    mtry = data.split$train.bal %>% ncol() %>% sqrt() %>% ceiling(),\n",
    "    replace = TRUE,\n",
    "#     cutoff = 1/2,\n",
    "#     sampsize = nrow(data.split$train.bal),\n",
    "    #     nodesize = 5,\n",
    "    oob.prox = FALSE\n",
    ") {\n",
    " \n",
    "\n",
    "    ####  Setup  ####\n",
    "\n",
    "    suppressWarnings({suppressMessages({\n",
    "        library(randomForest)\n",
    "    })})\n",
    "#     suppressWarnings({\n",
    "#         listLearners() %>%\n",
    "#             filter(\n",
    "#                 type == 'classif' &\n",
    "#                 name %>% str_detect('[Ff]orest')\n",
    "#             )\n",
    "#     })\n",
    "#     getParamSet('classif.randomForest')\n",
    "\n",
    "\n",
    "    ####  Task + Learner = Train  ####\n",
    "\n",
    "    rf.task = makeClassifTask(\n",
    "        id = 'rf.task',\n",
    "        data = data.split$train.bal %>%\n",
    "            select(\n",
    "                -newentered,\n",
    "                -qualified,\n",
    "                -funded_amount,\n",
    "                -type_formula,\n",
    "                -truefpd\n",
    "            ) %>% \n",
    "            filter(\n",
    "                parse(\n",
    "                    text = getRemoveNALogic(data.split = data.split)\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% as.data.frame(),\n",
    "        target = 'funded',\n",
    "        positive = 'TRUE'\n",
    "    )\n",
    "\n",
    "    rf.learner = makeLearner(\n",
    "        cl = 'classif.randomForest',\n",
    "        id = 'rf.learner',\n",
    "        ntree = ntree,\n",
    "        mtry = mtry,\n",
    "        replace = replace,\n",
    "#         cutoff = cutoff,\n",
    "#         sampsize = sampsize,\n",
    "#         nodesize = nodesize,\n",
    "        oob.prox = FALSE\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Hypertuning  ####\n",
    "\n",
    "#     rf.resample = makeResampleDesc('CV', iters = 5, stratify = TRUE)\n",
    "\n",
    "#     rf.params = makeParamSet(\n",
    "#     #     makeIntegerParam('mtry', lower = 4, upper = 12),\n",
    "#     #     makeNumericParam('nodesize', lower = 10, upper = 11)\n",
    "#     )\n",
    "\n",
    "#     rf.search = makeTuneControlGrid()\n",
    "\n",
    "#     rf.tune = tuneParams(\n",
    "#         task = rf.task,\n",
    "#         learner = rf.learner,\n",
    "#         resampling = rf.resample,\n",
    "#         par.set = rf.params,\n",
    "#         control = rf.search,\n",
    "#         measures = list(mmce, acc, fpr),\n",
    "#         show.info = FALSE\n",
    "#     )\n",
    "\n",
    "#     rf.tune$x\n",
    "\n",
    "#     # setHyperPars(\n",
    "#     #     learner = rf.learner,\n",
    "#     #     par.vals = rf.tune$x\n",
    "#     # ) \n",
    "\n",
    "\n",
    "\n",
    "    ####  Resampling  ####\n",
    "\n",
    "    # rf.cv = resample(\n",
    "    #     learner = rf.learner,\n",
    "    #     task = rf.task,\n",
    "    #     resampling = rf.resample,\n",
    "    #     measures = list(acc, mmce, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # rf.cv %>% .$measures.test\n",
    "    # rf.cv %>% .$aggr %>% as.data.frame()\n",
    "\n",
    "\n",
    "\n",
    "    ####  Training  ####\n",
    "\n",
    "    rf.model = train(\n",
    "        learner = rf.learner,\n",
    "        task = rf.task\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Evaluation  ####\n",
    "\n",
    "#     rf.predict = predict(\n",
    "#         object = rf.model,\n",
    "#         newdata = data.split$test %>%\n",
    "#             select(\n",
    "#                 -newentered,\n",
    "#                 -qualified,\n",
    "#                 -funded_amount,\n",
    "#                 -type_formula,\n",
    "#                 -truefpd\n",
    "#             )\n",
    "#     )\n",
    "\n",
    "#     rf.validate = predict(\n",
    "#         object = rf.model,\n",
    "#         newdata = data.split$validate %>%\n",
    "#             select(\n",
    "#                 -newentered,\n",
    "#                 -qualified,\n",
    "#                 -funded_amount,\n",
    "#                 -type_formula,\n",
    "#                 -truefpd\n",
    "#             )\n",
    "#     )\n",
    "    \n",
    "#     test.eval = rf.predict %>% getEvaluation()\n",
    "#     validate.eval = rf.validate %>% getEvaluation()\n",
    "\n",
    "#     if (evaluate) {\n",
    "#         list(\n",
    "#             test.eval = test.eval,\n",
    "#             validate.eval = validate.eval\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "    ####  Outputs  ####\n",
    "    \n",
    "    ##    Model    ##\n",
    "    return(rf.model)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "getVIP = function (rf.model) {\n",
    "    \n",
    "    df = rf.model$learner.model %>%\n",
    "        importance() %>%\n",
    "        as.data.frame() %>%\n",
    "        rownames_to_column(\n",
    "            var = 'variable'\n",
    "        ) %>%\n",
    "        arrange(\n",
    "            MeanDecreaseGini %>% desc()\n",
    "        )\n",
    "    \n",
    "    plot = rf.model$learner.model %>%\n",
    "        varImpPlot()\n",
    "    \n",
    "    list(\n",
    "        df = df,\n",
    "        plot = plot\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = data.split %>% getRandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf %>% getVIP()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
