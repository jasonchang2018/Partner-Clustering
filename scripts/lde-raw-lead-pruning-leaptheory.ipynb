{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library(devtools)\n",
    "# install_github(\n",
    "#     'jasonchang2018/opploansanalytics',\n",
    "#     auth_token = Sys.getenv('GITHUB_PAT_OPPLOANSANALYTICS')\n",
    "# )\n",
    "\n",
    "library(opploansanalytics)\n",
    "load.packages()\n",
    "\n",
    "library(mlr)\n",
    "library(pdp)\n",
    "library(vip)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#### Clarity Field Analysis ####\n",
    "clarityAnalysis = function () {\n",
    "\n",
    "# ####  Clarity Report Type Validation  ####\n",
    "# test %>%\n",
    "#     filter(\n",
    "#         ! report_received %>% str_detect('(?:FWB)?Leads01.*')\n",
    "#     ) %>% \n",
    "#     transmute(\n",
    "#         lead_id,\n",
    "#         report_received,\n",
    "#         report_requested,\n",
    "#         lead_time,\n",
    "#         report_time,\n",
    "#         lead.date = lead_time %>% as.Date(),\n",
    "#         report.date = report_time %>% as.Date(),\n",
    "#         diff = lead.date - report.date\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         diff\n",
    "#     )\n",
    "# #     ) %T>%\n",
    "# #     write.csv(\"..\\\\docs\\\\received-not-leads01.csv\")\n",
    "\n",
    "# test %>% group_by(report_received) %>% summarize(n = n()) %>% ungroup() %>% arrange(desc(n))\n",
    "\n",
    "#### Get Clarity Data\n",
    "\n",
    "####  Existing Fields  ####\n",
    "getClarityFields = function () {\n",
    "\n",
    "    a <- queryReporting(\n",
    "    \"\n",
    "    select\n",
    "        *\n",
    "    from\n",
    "        lde4.leads\n",
    "    where\n",
    "        --lead_time >= now()::date - '5 days'::interval\n",
    "        lead_id = '99f418da-8b66-471e-9586-f4112718ed21'\n",
    "    limit 100\n",
    "    \"\n",
    "    ) %>%\n",
    "        select(\n",
    "            lead_id,\n",
    "            clarity_report,\n",
    "            accepted\n",
    "        )\n",
    "\n",
    "    b <- a %>%\n",
    "        filter(\n",
    "            !is.na(clarity_report)\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            json.df = clarity_report %>% \n",
    "                map(\n",
    "                    .f = ~ .x %>%\n",
    "                        fromJSON() %>%\n",
    "                        .$xml_response %>% \n",
    "                        unlist() %>% \n",
    "                        as.data.frame(\n",
    "                            stringsAsFactors = FALSE\n",
    "                        ) %>% \n",
    "                        t()\n",
    "                )\n",
    "        )\n",
    "\n",
    "    all.fields <<- b %>%\n",
    "        filter(\n",
    "            lead_id == '99f418da-8b66-471e-9586-f4112718ed21'\n",
    "        ) %>%\n",
    "        .$clarity_report %>%\n",
    "        fromJSON(\n",
    "        ) %>% \n",
    "        .$xml_response %>% \n",
    "        unlist(\n",
    "        ) %>% \n",
    "        as.data.frame(\n",
    "            stringsAsFactors = FALSE\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            var = 'key'\n",
    "        ) %>% \n",
    "        rename(\n",
    "            value = \".\"\n",
    "        )\n",
    "\n",
    "    inquiry.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^inquiry\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                key %in% paste0(\n",
    "                    'inquiry.',\n",
    "                    c(\n",
    "                        'ofac_match',\n",
    "                        'ofac_score',\n",
    "                        'social_security_valid',\n",
    "                        'social_security_deceased',\n",
    "                        'ssn_distinct_first_last_name_count',\n",
    "                        'paycheck_direct_deposit',\n",
    "                        'bank_routing_valid',\n",
    "                        'inquiry_purpose_type'\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "    ccr.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^clear_credit_risk\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                !key %>% str_detect('inquiries\\\\.member_id') &\n",
    "                !key %>% str_detect('inquiry_received_at') &\n",
    "                !key %>% str_detect('inquiry_purpose_type') &\n",
    "                !key %>% str_detect('inquiry_tradeline_type') &\n",
    "                !key %>% str_detect('tradelines\\\\..*') &\n",
    "                !key %>% str_detect('stabilities\\\\..*') &\n",
    "                !key %>% str_detect('experian_attribute\\\\..*') &\n",
    "                !key %>% str_detect('description') &\n",
    "                !key %>% str_detect('full_name') &\n",
    "                !key %>% str_detect('code') &\n",
    "                !key %>% str_detect('date') &\n",
    "                !key %>% str_detect('first') &\n",
    "                !key %>% str_detect('48')\n",
    "#                 !key %>% str_detect('inquiry_purpose_type') & #keep\n",
    "#                 !key %>% str_detect('inquiry_tradeline_type') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.account_opened') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.highest_credit') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.amount_past_due') & #keep\n",
    "#                 !key %>% str_detect('tradelines\\\\.current_balance') & #keep\n",
    "            )\n",
    "\n",
    "    crh.fields <<-\n",
    "        all.fields %>%\n",
    "            filter(\n",
    "                key %>% str_detect('^clear_recent_history\\\\..*') &\n",
    "                value != '' &\n",
    "                !is.na(value)\n",
    "            ) %>% \n",
    "            filter(\n",
    "                !key %>% str_detect('tradeline_stabilities') &\n",
    "                !key %>% str_detect('date') &\n",
    "                !key %>% str_detect('name') &\n",
    "                !key %>% str_detect('\\\\d+')\n",
    "            )\n",
    "\n",
    "    rbind(\n",
    "        inquiry.fields,\n",
    "        ccr.fields,\n",
    "        crh.fields\n",
    "    ) %>% .$key\n",
    "    \n",
    "}\n",
    "\n",
    "####  Pull Test Clarity Report  ####\n",
    "test = queryReporting(\n",
    "\"\n",
    "select\n",
    "\n",
    "    --  Identifiers --\n",
    "    lde.lead_id\n",
    "    , lde.leadofferid\n",
    "    , lde.passthru_lead_offer_id\n",
    "    , lde.lead_time at time zone 'America/Chicago' as lead_time\n",
    "    , lde.partnerid\n",
    "\n",
    "    --  Credit  --\n",
    "    , case when lde.clarity_report notnull then TRUE else FALSE end as has_clarity\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'inquiry_received_at' as report_time\n",
    "    , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'received' as report_received\n",
    "    , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'requested_file' as report_requested\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ofac_score' as ofac_score\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'paycheck_direct_deposit' as paycheck_direct_deposit\n",
    "    , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ssn_distinct_first_last_name_count' as ssn_distinct_first_last_name_count\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'score' as ccr_score\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'clarity_seen' as ccr_clarity_seen\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_loans' as ccr_number_of_loans\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_bank_accounts' as ccr_number_of_bank_accounts\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'highest_number_of_days_past_due' as ccr_highest_number_of_days_past_due\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'current_inquiry_cluster_position' as ccr_current_inquiry_cluster_position\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_last_loan_charged_off' as ccr_days_since_last_loan_charged_off\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_inquiry_previously_seen' as ccr_days_since_inquiry_previously_seen\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_employers_last_six_months' as ccr_number_of_employers_last_six_months\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'loans_in_collections' as srh_loans_in_collections\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'spml_average_rollovers' as srh_spml_average_rollovers\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'amount_loans_charged_off' as srh_amount_loans_charged_off\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_opened_in_the_last_year' as srh_online_loan_opened_in_the_last_year\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_inquiry_in_the_last_thirty_days' as srh_online_loan_inquiry_in_the_last_thirty_days\n",
    "\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'ninety_days_ago' as ticrh_ninety_days_ago\n",
    "    , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'twentyfour_hours_ago' as ticrh_twentyfour_hours_ago\n",
    "\n",
    "\n",
    "    from\n",
    "        lde4.leads as lde\n",
    "    inner join\n",
    "        cloudlending.advertising_method as c_am\n",
    "        on lde.partnerid = c_am.external_id\n",
    "        and c_am.name = 'LenderEdge 4' \n",
    "    where\n",
    "        lde.accepted = TRUE\n",
    "        and lde.lead_time >= '2020-03-09'::date\n",
    "    limit 1000\n",
    "\"\n",
    ")\n",
    "\n",
    "####  Identify Data Types  ####\n",
    "not.features = c(\n",
    "    'lead_id',\n",
    "    'leadofferid',\n",
    "    'passthru_lead_offer_id',\n",
    "    'lead_time',\n",
    "    'partnerid',\n",
    "    'has_clarity',\n",
    "    'report_time',\n",
    "    'report_received',\n",
    "    'report_requested'\n",
    ")\n",
    "\n",
    "boolean.features = c(\n",
    "    'paycheck_direct_deposit',\n",
    "    'ccr_hit',\n",
    "    'ccr_clarity_seen',\n",
    "    'srh_online_loan_opened_in_the_last_year',\n",
    "    'srh_online_loan_inquiry_in_the_last_thirty_days'\n",
    ")\n",
    "\n",
    "numeric.features = colnames(test)[\n",
    "    which(\n",
    "        !colnames(test) %in% c(\n",
    "            boolean.features,\n",
    "            not.features,\n",
    "            'ccr_worst_payment_rating_null',\n",
    "            'ccr_worst_payment_rating_plus',\n",
    "            'ccr_worst_payment_rating_zero',\n",
    "            'ccr_worst_payment_rating_hash',\n",
    "            'ccr_worst_payment_rating_else',\n",
    "            'ccr_worst_payment_rating'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "processed.features = c(\n",
    "    'ccr_worst_payment_rating',\n",
    "    'ccr_days_since_last_loan_charged_off',\n",
    "    'ccr_days_since_last_loan_paid_off',\n",
    "    'ccr_days_since_last_ontime_payment',\n",
    "    'ccr_days_since_last_loan_payment',\n",
    "    'ccr_days_since_last_loan_opened'\n",
    ")\n",
    "\n",
    "impute.median = c(\n",
    "    'ccr_days_since_previous_bank_account_previously_seen',\n",
    "    'ccr_days_since_reported_income_previously_seen',\n",
    "    'ccr_days_since_inquiry_previously_seen',\n",
    "    'ccr_highest_number_of_days_past_due',\n",
    "    'paycheck_direct_deposit'\n",
    ")\n",
    "\n",
    "impute.mean = c(\n",
    "    'ccr_number_of_loans',\n",
    "    'ccr_number_of_bank_accounts',\n",
    "    'ccr_number_of_loans_paid_off',\n",
    "    'ccr_number_of_loans_paid_off',\n",
    "    'ccr_number_of_loans_past_due',\n",
    "    'ccr_current_inquiry_cluster_position',\n",
    "    'ccr_number_of_loans_current_and_open',\n",
    "    'ccr_number_of_employers_last_six_months',\n",
    "    'ccr_score'\n",
    ")\n",
    "\n",
    "correlated.features.numeric = c(\n",
    "    'icrh_ten_minutes_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_twenty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "    'icrh_thirty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "    'icrh_one_hour_ago',                                       #ccr_current_inquiry_cluster_position\n",
    "    'icrh_twentyfour_hours_ago',                               #ccr_current_inquiry_cluster_position\n",
    "    'icrh_seven_days_ago',                                     #ccr_current_inquiry_cluster_position\n",
    "    'icrh_thirty_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_ninety_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "    'icrh_recent_history_current_inquiry_cluster_position',    #ccr_current_inquiry_cluster_position\n",
    "    \n",
    "    'ticrh_seven_days_ago',                                    #ticrh_twentyfour_hours_ago\n",
    "    'ticrh_thirty_days_ago',                                   #ticrh_twentyfour_hours_ago\n",
    "    \n",
    "    'ccr_number_of_loans_paid_off',                            #ccr_number_of_loans\n",
    "    'ccr_number_of_loans_past_due',                            #ccr_number_of_loans\n",
    "    'ccr_number_of_loans_current_and_open',                    #ccr_number_of_loans,\n",
    "    'ccr_days_since_reported_income_previously_seen',          #ccr_days_since_inquiry_previously_seen\n",
    "    'ccr_days_since_previous_bank_account_previously_seen',    #ccr_days_since_inquiry_previously_seen\n",
    "    \n",
    "    'srh_amount_loans_in_collections',                         #srh_loans_in_collections\n",
    "    'srh_days_with_open_loans_in_the_last_ninety_days',        #srh_loans_in_collections\n",
    "    'srh_days_with_open_loans_in_the_last_year'                #srh_loans_in_collections\n",
    ")\n",
    "\n",
    "correlated.features.logical = c(\n",
    "    'ccr_hit',                                                 #ccr_clarity_seen\n",
    "    'ccr_worst_payment_rating_plus',                           #ccr_has_previous_loan_charged_off\n",
    "    'ccr_worst_payment_rating_null',                           #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_loan_payment',                           #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_ontime_payment',                         #ccr_has_previous_loan_opened  \n",
    "    'ccr_has_previous_loan_paid_off',                          #ccr_has_previous_loan_opened   \n",
    "    'ccr_has_previous_loan_charged_off'                        #ccr_has_previous_loan_opened  \n",
    ")\n",
    "\n",
    "#### Convert Data Types\n",
    "\n",
    "####  Convert Data Types  ####\n",
    "test.clean = test %>%\n",
    "    select(\n",
    "        -not.features\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = boolean.features[which(! boolean.features %in% correlated.features.numeric)],\n",
    "        .funs = as.logical\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = numeric.features[which(! numeric.features %in% correlated.features.numeric)],\n",
    "        .funs = as.numeric\n",
    "    ) %>% \n",
    "    mutate(\n",
    "        ccr_worst_payment_rating_null = is.na(ccr_worst_payment_rating),\n",
    "        ccr_worst_payment_rating_plus = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '+',\n",
    "        ccr_worst_payment_rating_zero = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '0',\n",
    "        ccr_worst_payment_rating_hash = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '#',\n",
    "        ccr_worst_payment_rating_else = !(\n",
    "            ccr_worst_payment_rating_plus |\n",
    "            ccr_worst_payment_rating_zero |\n",
    "            ccr_worst_payment_rating_hash |\n",
    "            ccr_worst_payment_rating_null\n",
    "        ),\n",
    "        \n",
    "        ccr_has_previous_loan_charged_off = ccr_days_since_last_loan_charged_off %>%\n",
    "            getClarityMapping()$convertDaysChargedOff(),\n",
    "        ccr_has_previous_loan_paid_off = ccr_days_since_last_loan_paid_off %>% \n",
    "            getClarityMapping()$convertDaysPaidOff(),\n",
    "        ccr_has_previous_ontime_payment = ccr_days_since_last_ontime_payment %>% \n",
    "            getClarityMapping()$convertDaysOntimePayment(),\n",
    "        ccr_has_previous_loan_payment = ccr_days_since_last_loan_payment %>% \n",
    "            getClarityMapping()$convertDaysAnyPayment(),\n",
    "        ccr_has_previous_loan_opened = ccr_days_since_last_loan_opened %>% \n",
    "            getClarityMapping()$convertDaysLoanOpened()\n",
    "        \n",
    "        \n",
    "    ) %>%\n",
    "    select(\n",
    "        -processed.features\n",
    "    )\n",
    "# test.clean %>% str()\n",
    "\n",
    "#### Impute\n",
    "\n",
    "####  Examine Values in Field  ####\n",
    "field = quo(paycheck_direct_deposit)\n",
    "\n",
    "test.clean[[quo_name(field)]] %>% median(na.rm = TRUE)\n",
    "test.clean[[quo_name(field)]] %>% mean(na.rm = TRUE)\n",
    "\n",
    "test %>%\n",
    "    group_by(\n",
    "#         var = !!field %>% as.numeric\n",
    "        var = !!field\n",
    "    ) %>% \n",
    "    summarize(\n",
    "        n = n()\n",
    "    ) %>%\n",
    "    ungroup() %>%\n",
    "#     filter(\n",
    "#         !is.na(var)\n",
    "#         var < 100\n",
    "#     ) %>% \n",
    "    arrange(\n",
    "#         desc(n)\n",
    "        var\n",
    "#     )\n",
    "    ) %>% ggplot(aes(x = var, y = n)) + geom_bar(stat = 'identity')\n",
    "\n",
    "####  Impute and/or Remove Missing Values  ####\n",
    "test.impute.value = test.clean %>%\n",
    "    mutate_at(\n",
    "        .vars = impute.median[ which(! impute.median %in% correlated.features.numeric) ],\n",
    "        .funs = ~ .x %>%\n",
    "            replace_na(\n",
    "                replace = .x %>% median(na.rm = TRUE)\n",
    "            )\n",
    "    ) %>%\n",
    "    mutate_at(\n",
    "        .vars = impute.mean[ which(! impute.mean %in% correlated.features.numeric) ],\n",
    "        .funs = ~ .x %>%\n",
    "            replace_na(\n",
    "                replace = .x %>% mean(na.rm = TRUE)\n",
    "            )\n",
    "    ) %>% \n",
    "    mutate(\n",
    "        paycheck_direct_deposit = paycheck_direct_deposit %>% as.logical()\n",
    "    )\n",
    "\n",
    "test.impute = test.impute.value %>% \n",
    "    filter(\n",
    "        apply(\n",
    "            X = test.impute.value,\n",
    "            FUN = function (x) { x %>% is.na() %>% sum() },\n",
    "            MARGIN = 1\n",
    "        ) == 0\n",
    "    )\n",
    "\n",
    "#### Numeric Collinearity\n",
    "\n",
    "####  Calculate Correlation Matrix (Numeric)  ####\n",
    "test.numeric.cor = test.impute %>%\n",
    "    select(\n",
    "        numeric.features[ which(!numeric.features %in% processed.features)]\n",
    "    ) %>% \n",
    "    cor()\n",
    "\n",
    "test.numeric.cor[upper.tri(test.numeric.cor)] = NA\n",
    "test.numeric.cor.upper = test.numeric.cor %>% melt(na.rm = TRUE)\n",
    "\n",
    "# ####  Sum Missing (NA) Values for Numeric  ####\n",
    "# apply(\n",
    "# #     X = test.clean %>%\n",
    "#     X = test.impute %>%\n",
    "#         select(\n",
    "#             numeric.features[ which(!numeric.features %in% c(processed.features, correlated.features.numeric)) ]\n",
    "#         ),\n",
    "#     FUN = function (x) { is.na(x) %>% sum() },\n",
    "#     MARGIN = 2\n",
    "# ) %>% \n",
    "# as.data.frame() %>% select(n = '.') %>% rownames_to_column('field') %>% arrange(desc(n))\n",
    "\n",
    "# ####  Find / Remove Collinear Features (Numeric)  ####\n",
    "# correlated.features.numeric = c(\n",
    "#     'icrh_ten_minutes_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_twenty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_thirty_minutes_ago',                                 #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_one_hour_ago',                                       #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_twentyfour_hours_ago',                               #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_seven_days_ago',                                     #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_thirty_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_ninety_days_ago',                                    #ccr_current_inquiry_cluster_position\n",
    "#     'icrh_recent_history_current_inquiry_cluster_position',    #ccr_current_inquiry_cluster_position\n",
    "    \n",
    "#     'ticrh_seven_days_ago',                                    #ticrh_twentyfour_hours_ago\n",
    "#     'ticrh_thirty_days_ago',                                   #ticrh_twentyfour_hours_ago\n",
    "    \n",
    "#     'ccr_number_of_loans_paid_off',                            #ccr_number_of_loans\n",
    "#     'ccr_number_of_loans_past_due',                            #ccr_number_of_loans\n",
    "#     'ccr_number_of_loans_current_and_open',                    #ccr_number_of_loans,\n",
    "#     'ccr_days_since_reported_income_previously_seen',          #ccr_days_since_inquiry_previously_seen\n",
    "#     'ccr_days_since_previous_bank_account_previously_seen',    #ccr_days_since_inquiry_previously_seen\n",
    "    \n",
    "#     'srh_amount_loans_in_collections',                         #srh_loans_in_collections\n",
    "#     'srh_days_with_open_loans_in_the_last_ninety_days',        #srh_loans_in_collections\n",
    "#     'srh_days_with_open_loans_in_the_last_year'                #srh_loans_in_collections\n",
    "# )\n",
    "\n",
    "# test.numeric.cor.upper.removed = test.numeric.cor.upper %>% \n",
    "#     filter(\n",
    "#         Var1 != Var2\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         desc(value)\n",
    "#     ) %>% \n",
    "#     filter(\n",
    "#         ! Var1 %in% correlated.features.numeric &\n",
    "#         ! Var2 %in% correlated.features.numeric\n",
    "#     ) %>% \n",
    "# #     group_by(\n",
    "# #         Var1\n",
    "# #     ) %>% \n",
    "# #     summarize(\n",
    "# #         n = n(),\n",
    "# #         total.cor = sum(value^2)\n",
    "# #     ) %>% \n",
    "# #     ungroup() %>% \n",
    "#     arrange(\n",
    "# #         total.cor %>% desc\n",
    "#         value %>% desc\n",
    "#     )\n",
    "\n",
    "# test.numeric.cor.upper.removed %T>%\n",
    "#     head() %>% \n",
    "#     ggplot(\n",
    "#         mapping = aes(\n",
    "#             x = Var1,\n",
    "#             y = Var2,\n",
    "#             fill = value\n",
    "#         )\n",
    "#     ) +\n",
    "#     geom_tile(\n",
    "#         color = 'white'\n",
    "#     ) +\n",
    "#     scale_fill_gradient2(\n",
    "#         low = \"blue\",\n",
    "#         high = \"red\",\n",
    "#         mid = \"white\", \n",
    "#         midpoint = 0,\n",
    "#         limit = c(-1,1),\n",
    "#         space = \"Lab\", \n",
    "#         name=\"Pearson\\nCorrelation\"\n",
    "#     ) +\n",
    "#     theme_minimal() +\n",
    "#     theme(\n",
    "#         axis.text.x = element_text(\n",
    "#             angle = -45,\n",
    "#             hjust = 0\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#### Boolean Collinearity\n",
    "\n",
    "####  Calculate Correlation Matrix (Boolean)  ####\n",
    "test.logical.cor = test.impute %>%\n",
    "    select(\n",
    "        -c(numeric.features[ which(!numeric.features %in% processed.features)])\n",
    "    ) %>%\n",
    "    cor()\n",
    "\n",
    "test.logical.cor[upper.tri(test.logical.cor)] = NA\n",
    "test.logical.cor.upper = test.logical.cor %>% melt(na.rm = TRUE)\n",
    "\n",
    "# ####  Find / Remove Collinear Features (Logical)  ####\n",
    "# correlated.features.logical = c(\n",
    "#     'ccr_hit',                               # ccr_clarity_seen\n",
    "#     'ccr_worst_payment_rating_plus',         # ccr_has_previous_loan_charged_off\n",
    "#     'ccr_worst_payment_rating_null',         # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_loan_payment',         # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_ontime_payment',       # ccr_has_previous_loan_opened  \n",
    "#     'ccr_has_previous_loan_paid_off',        # ccr_has_previous_loan_opened   \n",
    "#     'ccr_has_previous_loan_charged_off'      # ccr_has_previous_loan_opened  \n",
    "# )\n",
    "\n",
    "# test.logical.cor.upper.removed = test.logical.cor.upper %>% \n",
    "#     filter(\n",
    "#         Var1 != Var2\n",
    "#     ) %>% \n",
    "#     arrange(\n",
    "#         desc(value)\n",
    "# #         value\n",
    "#     ) %>% \n",
    "#     filter(\n",
    "#         ! Var1 %in% correlated.features.logical &\n",
    "#         ! Var2 %in% correlated.features.logical\n",
    "# #     ) %>% \n",
    "# #     group_by(\n",
    "# #         Var1\n",
    "# #     ) %>% \n",
    "# #     summarize(\n",
    "# #         n = n(),\n",
    "# #         total.cor = sum(value^2)\n",
    "# #     ) %>% \n",
    "# #     ungroup() %>% \n",
    "# #     arrange(\n",
    "# #         total.cor %>% desc\n",
    "#     )\n",
    "\n",
    "# test.logical.cor.upper.removed\n",
    "\n",
    "# test.logical.cor.upper.removed %>%\n",
    "#     ggplot(\n",
    "#         mapping = aes(\n",
    "#             x = Var1,\n",
    "#             y = Var2,\n",
    "#             fill = value\n",
    "#         )\n",
    "#     ) +\n",
    "#     geom_tile(\n",
    "#         color = 'white'\n",
    "#     ) +\n",
    "#     scale_fill_gradient2(\n",
    "#         low = \"blue\",\n",
    "#         high = \"red\",\n",
    "#         mid = \"white\", \n",
    "#         midpoint = 0,\n",
    "#         limit = c(-1,1),\n",
    "#         space = \"Lab\", \n",
    "#         name=\"Pearson\\nCorrelation\"\n",
    "#     ) +\n",
    "#     theme_minimal() +\n",
    "#     theme(\n",
    "#         axis.text.x = element_text(\n",
    "#             angle = -45,\n",
    "#             hjust = 0\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# getClarityMapping = function () {\n",
    "    \n",
    "#     convertInquiryPurposeType = function (purpose.code) {\n",
    "        \n",
    "#         case_when(\n",
    "#             purpose.code == 'AR' ~ 'New Credit',\n",
    "#             purpose.code == 'AS' ~ 'New Credit Soft',\n",
    "#             purpose.code == 'RA' ~ 'Account Review Soft',\n",
    "#             purpose.code == 'RP' ~ 'Consumer Inquiry Soft',\n",
    "#             purpose.code == 'CL' ~ 'Collection Inquiry',\n",
    "#             purpose.code == 'PC' ~ 'Pre-check Soft',\n",
    "#             purpose.code == 'MS' ~ 'Credit Monitor Soft',\n",
    "#             purpose.code == 'CC' ~ 'Check Cash',\n",
    "#             purpose.code == 'CS' ~ 'Collection Soft',\n",
    "#             purpose.code == 'PS' ~ 'Pre-screen Soft',\n",
    "#             purpose.code == 'IV' ~ 'Item Verification',\n",
    "#             purpose.code == 'IS' ~ 'Item Verification Soft',\n",
    "#             purpose.code == 'EH' ~ 'Employment',\n",
    "#             purpose.code == 'ES' ~ 'Employment Soft',\n",
    "#             purpose.code == 'LH' ~ 'Lease',\n",
    "#             purpose.code == 'LS' ~ 'Lease Soft',\n",
    "#             purpose.code == 'WS' ~ 'Written Authorization Soft',\n",
    "#             purpose.code == 'WH' ~ 'Written Authorization - Hard',\n",
    "#             purpose.code == 'PR' ~ 'Portfolio Review',\n",
    "#             purpose.code == 'PA' ~ 'Portfolio Acquisition',\n",
    "#             purpose.code == 'SP' ~ 'Subpoena',\n",
    "#             TRUE ~ 'Other'\n",
    "#         )\n",
    "#     }\n",
    "#     convertWorstPaymentRatingCCR = function (rating) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(rating) ~ 0,\n",
    "#             rating == '+' ~ 1,\n",
    "#             rating == '0' ~ 2,\n",
    "#             rating == '#' ~ 3,\n",
    "#             rating == '@' ~ 4,\n",
    "#             rating == 'X' ~ 5,\n",
    "#             rating == '4' ~ 6,\n",
    "#             rating == 'V' ~ 7,\n",
    "#             rating == 'W' ~ 8,\n",
    "#             rating == '1' ~ 9,\n",
    "#             rating == '5' ~ 10,\n",
    "#             rating == 'B' ~ 11,\n",
    "#             rating == 'L' ~ 12,\n",
    "#             rating == '7' ~ 13,\n",
    "#             rating == '8' ~ 14,\n",
    "#             rating == 'C' ~ 15,\n",
    "#             rating == 'D' ~ 16,\n",
    "#             rating == 'E' ~ 17,\n",
    "#             rating == 'H' ~ 18,\n",
    "#             rating == 'U' ~ 19,\n",
    "#             rating == 'Y' ~ 20,\n",
    "#             rating == 'Z' ~ 21,\n",
    "#             TRUE ~ 22\n",
    "#         )\n",
    "#     }\n",
    "#     convertDaysChargedOff = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysPaidOff = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysOntimePayment = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysAnyPayment = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "#     convertDaysLoanOpened = function (days) {\n",
    "        \n",
    "#         case_when(\n",
    "#             is.na(days) ~ FALSE,\n",
    "#             TRUE ~ TRUE\n",
    "#         )\n",
    "        \n",
    "#     }\n",
    "    \n",
    "#     list(\n",
    "#         convertInquiryPurposeType = convertInquiryPurposeType,\n",
    "#         convertWorstPaymentRatingCCR = convertWorstPaymentRatingCCR,\n",
    "#         convertDaysChargedOff = convertDaysChargedOff,\n",
    "#         convertDaysPaidOff = convertDaysPaidOff,\n",
    "#         convertDaysOntimePayment = convertDaysOntimePayment,\n",
    "#         convertDaysAnyPayment = convertDaysAnyPayment,\n",
    "#         convertDaysLoanOpened = convertDaysLoanOpened\n",
    "#     )\n",
    "        \n",
    "# }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getShortenedAdmethodName = function (admethod) {\n",
    "    \n",
    "    admethod %>%\n",
    "        str_to_lower() %>% \n",
    "        str_match_all(\n",
    "            pattern = regex(\n",
    "                \"(.*?)(?:\\\\s4)?$\"\n",
    "            )\n",
    "        ) %>% \n",
    "        .[[1]] %>% .[,2] %>% .[1] %>%\n",
    "        str_replace_all(\n",
    "            pattern = ' ',\n",
    "            replacement = ''\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     92
    ]
   },
   "outputs": [],
   "source": [
    "getLeadsPerformance = function (admethod, timestart='2019-11-01', timeend='2020-02-01', limit=NA, write=FALSE) {\n",
    "    \n",
    "    getLeadsDF = function (admethod, timestart, timeend, limit = NA) {\n",
    "    \n",
    "        queryReporting(\n",
    "            paste0(\n",
    "    \"\n",
    "    select\n",
    "\n",
    "        --  Identifiers --\n",
    "        lde.lead_id\n",
    "        , lde.leadofferid\n",
    "        , lde.lead_time at time zone 'America/Chicago' as lead_time\n",
    "        , extract(day from lde.lead_time at time zone 'America/Chicago') as lead_day\n",
    "        , lde.partnerid\n",
    "        , lde.email\n",
    "\n",
    "        --  Outcome  --\n",
    "        , lde.accepted\n",
    "        , lde.reason\n",
    "        , lde.code\n",
    "\n",
    "        --  Bank  --\n",
    "        , lde.bankname\n",
    "        , lde.abaroutingnumber\n",
    "        , lde.accountnumber\n",
    "\n",
    "        --  Income  --\n",
    "        , lde.grossmonthlyincome\n",
    "        , lde.incometype\n",
    "        , lde.payrollfrequency\n",
    "        , lde.payrolltype\n",
    "        , lde.lastpayrolldate\n",
    "\n",
    "        --  Identity  --\n",
    "        , lde.dateofbirth\n",
    "        , floor((lde.lead_time::date - lde.dateofbirth::date)::numeric/365) as age\n",
    "        , lde.statecode\n",
    "\n",
    "        --  Employment  --\n",
    "        , lde.work_hiredate\n",
    "\n",
    "        --  Offer  --\n",
    "        , lde.offer_amount\n",
    "        , lde.offer_interestrate\n",
    "        , lde.offer_monthlypayment\n",
    "        , (lde.raw_lead ->> 'requestedLoanAmount')::numeric as requestedLoanAmount\n",
    "        , lde.raw_lead -> 'campaign_id' as campaign_id\n",
    "\n",
    "        --  Credit  --\n",
    "        , case when lde.clarity_report notnull then TRUE else FALSE end as has_clarity\n",
    "        , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'inquiry_received_at' as report_time\n",
    "        , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'received' as report_received\n",
    "        , lde.clarity_report -> 'xml_response' -> 'opploans' ->> 'requested_file' as report_requested\n",
    "\n",
    "        , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ofac_score' as ofac_score\n",
    "        , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'paycheck_direct_deposit' as paycheck_direct_deposit\n",
    "        , lde.clarity_report -> 'xml_response' -> 'inquiry' ->> 'ssn_distinct_first_last_name_count' as ssn_distinct_first_last_name_count\n",
    "\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'score' as ccr_score\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_loans' as ccr_number_of_loans\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_bank_accounts' as ccr_number_of_bank_accounts\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'highest_number_of_days_past_due' as ccr_highest_number_of_days_past_due\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'current_inquiry_cluster_position' as ccr_current_inquiry_cluster_position\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_last_loan_charged_off' as ccr_days_since_last_loan_charged_off\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'days_since_inquiry_previously_seen' as ccr_days_since_inquiry_previously_seen\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'number_of_employers_last_six_months' as ccr_number_of_employers_last_six_months\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_credit_risk' ->> 'worst_payment_rating' as ccr_worst_payment_rating\n",
    "\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'loans_in_collections' as srh_loans_in_collections\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'spml_average_rollovers' as srh_spml_average_rollovers\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'amount_loans_charged_off' as srh_amount_loans_charged_off\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_opened_in_the_last_year' as srh_online_loan_opened_in_the_last_year\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'supplier_recent_history' -> 'summary_recent_history' ->> 'online_loan_inquiry_in_the_last_thirty_days' as srh_online_loan_inquiry_in_the_last_thirty_days\n",
    "\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'ninety_days_ago' as ticrh_ninety_days_ago\n",
    "        , lde.clarity_report -> 'xml_response' -> 'clear_recent_history' -> 'inquiry_cluster_recent_history' -> 'total_inquiry_clusters_recent_history' ->> 'twentyfour_hours_ago' as ticrh_twentyfour_hours_ago\n",
    "\n",
    "    from\n",
    "        lde4.leads as lde\n",
    "    inner join\n",
    "        cloudlending.advertising_method as c_am\n",
    "        on lde.partnerid = c_am.external_id\n",
    "        and c_am.name = '\", admethod, \"' \n",
    "    where\n",
    "        lde.accepted = TRUE\n",
    "        and lde.lead_time >= '\", timestart, \"'::date\n",
    "        and lde.lead_time < '\", timeend, \"'::date\n",
    "    \", ifelse(is.na(limit), \"\", paste0(\"limit \", limit))\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    getFunnelDF = function (admethod, timestart, timeend) {\n",
    "        queryReporting(paste0(\n",
    "    \"\n",
    "    with status as\n",
    "    (\n",
    "        select\n",
    "            c_app.id as application\n",
    "            , c_app.lde4_lead_id as lead_id\n",
    "            , c_app.createddate at time zone 'America/Chicago' as appldate\n",
    "            , c_app.funded_amount\n",
    "            , c_app.type_formula\n",
    "\n",
    "            , max(case  when new_value = 'NEW - ENTERED'\n",
    "                        then 1 else 0\n",
    "                        end) as newentered\n",
    "            , max(case  when old_value = 'NEW - ENTERED'\n",
    "                        and new_value = 'BUSINESS RULES PASSED'\n",
    "                        then 1 else 0\n",
    "                        end) as bizrulespassed\n",
    "\n",
    "            , max(case  when new_value = 'BUREAU APPROVED'\n",
    "                        then 1 else 0\n",
    "                        end) as qualified\n",
    "\n",
    "            , max(case  when new_value in ('BANK VERIFICATION COMPLETED', 'NEW - SCORECARD GENERATED')\n",
    "                        then 1 else 0\n",
    "                        end) as bankverified\n",
    "\n",
    "            , max(case  when c_ash.old_value = 'NEW - PRICING GENERATED'\n",
    "                        and c_ash.new_value in ('CONTRACT SIGNED', 'WAITING ON STIPULATIONS')\n",
    "                        then 1 else 0\n",
    "                        end) as passscorecardratecard\n",
    "\n",
    "            , max(case  when c_ash.old_value in ('NEW - PRICING GENERATED', 'WAITING ON STIPULATIONS')\n",
    "                        and c_ash.new_value = 'CONTRACT SIGNED'\n",
    "                        then 1 else 0 end) as contractsigned\n",
    "\n",
    "            , max(case  when c_ash.new_value = 'LOAN APPROVED'\n",
    "                        then 1 else 0\n",
    "                        end) as funded\n",
    "        from\n",
    "            cloudlending.applications as c_app\n",
    "            inner join\n",
    "                cloudlending.advertising_method as c_am\n",
    "                on c_app.advertising_method = c_am.id\n",
    "                and c_am.name = '\", admethod, \"'\n",
    "            inner join\n",
    "                cloudlending.application_status_history as c_ash\n",
    "                on c_app.id = c_ash.application\n",
    "        where\n",
    "            c_app.createddate at time zone 'America/Chicago' >= '\", timestart, \"'\n",
    "            and c_app.createddate at time zone 'America/Chicago' < '\", timeend, \"'\n",
    "        group by\n",
    "            1,2,3,4,5\n",
    "    )\n",
    "    , cs_decisioned_apps as\n",
    "    (\n",
    "        select\n",
    "            c_app.id as application\n",
    "        from\n",
    "            cloudlending.applications as c_app\n",
    "            inner join\n",
    "                status\n",
    "                on c_app.id = status.application\n",
    "                and status.contractsigned = 1\n",
    "        where\n",
    "            denialreason not in ('Time In Pending', 'Withdraw')\n",
    "            or (denialreason isnull and status = 'LOAN APPROVED')\n",
    "    )\n",
    "    select\n",
    "        status.application\n",
    "        , status.lead_id\n",
    "        , status.appldate\n",
    "        , status.type_formula\n",
    "        , status.funded_amount\n",
    "        , status.newentered\n",
    "        , status.bizrulespassed\n",
    "        , status.qualified\n",
    "        , status.bankverified\n",
    "        , status.passscorecardratecard\n",
    "        , status.contractsigned\n",
    "        , case when cs_decisioned_apps.application notnull then 1 else 0 end as cs_decisioned\n",
    "        , status.funded\n",
    "    from\n",
    "      status\n",
    "      left join\n",
    "        cs_decisioned_apps\n",
    "        on status.application = cs_decisioned_apps.application\n",
    "    \"\n",
    "    ))\n",
    "    }\n",
    "    \n",
    "    leads <<- getLeadsDF(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = limit\n",
    "    )\n",
    "    \n",
    "    funnel <<- getFunnelDF(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend\n",
    "    )\n",
    "    \n",
    "    loan.performance <<- queryReporting(\n",
    "    \"\n",
    "    select\n",
    "        applicationid as application\n",
    "        , truefpd\n",
    "    from\n",
    "        tableau_reporting.tbl_pd_rate_loan_level\n",
    "    where\n",
    "        appldate >= '2019-10-01'::date\n",
    "    \"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = leads %>%\n",
    "        left_join(\n",
    "            funnel,\n",
    "            by = 'lead_id'\n",
    "        ) %>% \n",
    "        left_join(\n",
    "            loan.performance,\n",
    "            by = 'application'\n",
    "        ) %>% \n",
    "        mutate_at(\n",
    "            .vars = colnames(funnel %>% select(-application, -lead_id, -appldate, -funded_amount, -type_formula)),\n",
    "            .funs = function (x) { x %>% replace_na(replace = 0) %>% as.logical() }\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (write) {\n",
    "        df %>%\n",
    "            write.csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-\",\n",
    "                    timestart,\n",
    "                    \".csv\"\n",
    "                )\n",
    "            )\n",
    "    }\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "convertDataTypes = function (raw.df) {\n",
    "    \n",
    "    data.type.list = list(\n",
    "        booleans = c(\n",
    "            'paycheck_direct_deposit',\n",
    "            'srh_online_loan_opened_in_the_last_year',\n",
    "            'srh_online_loan_inquiry_in_the_last_thirty_days'\n",
    "        ),\n",
    "        numerics = c(\n",
    "            'paycheck_direct_deposit',\n",
    "            'ofac_score',\n",
    "            'ssn_distinct_first_last_name_count',\n",
    "            'ccr_score',\n",
    "            'ccr_number_of_loans',\n",
    "            'ccr_number_of_bank_accounts',\n",
    "            'ccr_highest_number_of_days_past_due',\n",
    "            'ccr_current_inquiry_cluster_position',\n",
    "            'ccr_days_since_last_loan_charged_off',\n",
    "            'ccr_days_since_inquiry_previously_seen',\n",
    "            'ccr_number_of_employers_last_six_months',\n",
    "            'srh_loans_in_collections',\n",
    "            'srh_spml_average_rollovers',\n",
    "            'srh_amount_loans_charged_off',\n",
    "            'ticrh_ninety_days_ago',\n",
    "            'ticrh_twentyfour_hours_ago'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    raw.df %>% \n",
    "        mutate_at(\n",
    "            .vars = data.type.list$booleans,\n",
    "            .funs = as.logical\n",
    "        ) %>%  \n",
    "        mutate_at(\n",
    "            .vars = data.type.list$numerics,\n",
    "            .funs = as.numeric\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "processColumns = function (converted.df) {\n",
    "\n",
    "    converted.df %>% \n",
    "        mutate(\n",
    "            ccr_worst_payment_rating_null = is.na(ccr_worst_payment_rating),\n",
    "            ccr_worst_payment_rating_plus = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '+',\n",
    "            ccr_worst_payment_rating_zero = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '0',\n",
    "            ccr_worst_payment_rating_hash = !ccr_worst_payment_rating_null & ccr_worst_payment_rating == '#',\n",
    "            ccr_worst_payment_rating_else = !(\n",
    "                ccr_worst_payment_rating_plus |\n",
    "                ccr_worst_payment_rating_zero |\n",
    "                ccr_worst_payment_rating_hash |\n",
    "                ccr_worst_payment_rating_null\n",
    "            ),\n",
    "\n",
    "            ccr_has_previous_loan_charged_off = case_when(\n",
    "                is.na(ccr_days_since_last_loan_charged_off) ~ FALSE,\n",
    "                TRUE ~ TRUE\n",
    "            ),\n",
    "            \n",
    "            payrolltype = payrolltype %>% replace_na('Missing'),\n",
    "            campaign_id = campaign_id %>% map(~ .x %>% str_match_all(\"\\\\\\\"(.*)\\\\\\\"\") %>% .[[1]] %>% .[,2]) %>% as.character()\n",
    "            \n",
    "        ) %>% \n",
    "        select(\n",
    "            -ccr_worst_payment_rating,\n",
    "            -ccr_days_since_last_loan_charged_off\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "imputeMissingValues = function (processed.df) {\n",
    "    \n",
    "\n",
    "    impute.10000 = c(\n",
    "        'ccr_days_since_inquiry_previously_seen',\n",
    "        'ccr_number_of_loans',\n",
    "        'ccr_number_of_bank_accounts',\n",
    "        'ccr_highest_number_of_days_past_due',\n",
    "        'ccr_current_inquiry_cluster_position',\n",
    "        'ccr_number_of_employers_last_six_months',\n",
    "        'ccr_score',\n",
    "        'paycheck_direct_deposit'\n",
    "    )\n",
    "    \n",
    "    processed.df %>%\n",
    "        mutate_at(\n",
    "            .vars = impute.10000,\n",
    "            .funs = ~ .x %>%\n",
    "                replace_na(\n",
    "                    replace = 10000\n",
    "                )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "standardizeValues = function (imputed.df) {\n",
    "    return(imputed.df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "keepModelFeatures = function (standardized.df) {\n",
    "    \n",
    "    standardized.df %>% \n",
    "        select(\n",
    "            -lead_id,\n",
    "            -leadofferid,\n",
    "            -lead_time,\n",
    "            -partnerid,\n",
    "            -accepted,\n",
    "            -reason,\n",
    "            -code,\n",
    "            -campaign_id,\n",
    "            -bankname,\n",
    "            -abaroutingnumber,\n",
    "            -accountnumber,\n",
    "            -incometype,\n",
    "            -payrollfrequency,\n",
    "            -payrolltype,\n",
    "            -work_hiredate,\n",
    "            -lastpayrolldate,\n",
    "            -dateofbirth,\n",
    "            -report_time,\n",
    "            -has_clarity,\n",
    "            -report_requested,\n",
    "            -report_received,\n",
    "            -report_time,\n",
    "            -appldate,\n",
    "#             -newentered,\n",
    "            -bizrulespassed,\n",
    "#             -qualified,\n",
    "            -bankverified,\n",
    "            -passscorecardratecard,\n",
    "            -contractsigned,\n",
    "            -cs_decisioned,\n",
    "            -offer_interestrate,\n",
    "            -offer_monthlypayment,\n",
    "            -offer_amount,\n",
    "            -application\n",
    "        ) %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.character,\n",
    "            .funs = as.factor\n",
    "        ) %>% \n",
    "        mutate_if(\n",
    "            .predicate = is.logical,\n",
    "            .funs = as.factor\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "removeMissingObservations = function (feature.df) {\n",
    "    \n",
    "    feature.df %>% \n",
    "#         mutate(\n",
    "        filter(\n",
    "            apply(\n",
    "                X = feature.df,\n",
    "                FUN = function (x) { x %>% is.na() %>% sum() },\n",
    "                MARGIN = 1\n",
    "            ) == 0\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getColPercNA = function (df) {\n",
    "\n",
    "    df %>% \n",
    "        apply(\n",
    "            FUN = function (x) {\n",
    "                x %>% is.na() %>% mean()\n",
    "            },\n",
    "            MARGIN = 2\n",
    "        ) %>% \n",
    "        as.data.frame() %>% \n",
    "        select(\n",
    "            perc.na = '.'\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            var = 'column'\n",
    "        ) %>% \n",
    "        arrange(\n",
    "            perc.na %>% desc()\n",
    "        )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeTraining = function (admethod = 'LeapTheory 4') {\n",
    "    \n",
    "    df.feb =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2020-02-01',\n",
    "            timeend = '2020-02-23',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "    df.jan =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2020-01-01',\n",
    "            timeend = '2020-02-01',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "    df.dec =\n",
    "        getLeadsPerformance(\n",
    "            admethod = admethod,\n",
    "            timestart = '2019-12-01',\n",
    "            timeend = '2020-01-01',\n",
    "            limit = NA,\n",
    "            write = TRUE\n",
    "        )\n",
    "\n",
    "\n",
    "    df = do.call(\n",
    "        rbind,\n",
    "        list(df.feb, df.jan, df.dec)\n",
    "    )\n",
    "    \n",
    "    df %>% write.csv(\n",
    "        paste0(\n",
    "            \"..\\\\data\\\\df-\",\n",
    "            admethod %>% getShortenedAdmethodName(),\n",
    "            \".csv\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readTraining = function (admethod = 'LeapTheory 4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeTraining()\n",
    "    \n",
    "    df.feb =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2020-02-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "\n",
    "    df.jan =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2020-01-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "\n",
    "    df.dec =\n",
    "        suppressMessages({suppressWarnings({\n",
    "            read_csv(\n",
    "                paste0(\n",
    "                    \"..\\\\data\\\\df-\",\n",
    "                    admethod %>% getShortenedAdmethodName(),\n",
    "                    \"-2019-12-01.csv\"\n",
    "                )\n",
    "            ) %>%\n",
    "                select(-X1)\n",
    "        })}) %>% \n",
    "        convertDataTypes() %>%\n",
    "        processColumns() %>%\n",
    "        imputeMissingValues() %>%\n",
    "#         standardizeValues() %>% \n",
    "        keepModelFeatures()\n",
    "#         removeMissingObservations()\n",
    "    \n",
    "    df = do.call(\n",
    "        rbind,\n",
    "        list(df.feb, df.jan, df.dec)\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     df = do.call(\n",
    "#         what = rbind,\n",
    "#         args = lapply(\n",
    "#             X = c(\n",
    "#                 \"..\\\\data\\\\df-lenderedge-2020-01-01.csv\",\n",
    "#                 \"..\\\\data\\\\df-lenderedge-2020-02-01.csv\"\n",
    "#             ),\n",
    "#             FUN = function (x) {\n",
    "#                 suppressWarnings({suppressMessages({\n",
    "#                     read_csv(x)\n",
    "#                 })})\n",
    "#             }\n",
    "#         )\n",
    "#     ) %>% select(-X1)\n",
    "    \n",
    "    return(df)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.train = readTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeTest = function (admethod = 'LeapTheory 4', timestart = '2020-03-01', timeend = '2020-03-08') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-test.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readTest = function (admethod = 'LeapTheory 4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeTest()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-01.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.test = readTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate = function (admethod = 'LeapTheory 4', timestart = '2020-02-23', timeend = '2020-03-01') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate = function (admethod = 'LeapTheory 4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-02-23.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate = readValidate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Additional Validates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "writeValidate2 = function (admethod = 'LeapTheory 4', timestart = '2020-03-08', timeend = '2020-03-15') {\n",
    "    \n",
    "    getLeadsPerformance(\n",
    "        admethod = admethod,\n",
    "        timestart = timestart,\n",
    "        timeend = timeend,\n",
    "        limit = NA,\n",
    "        write = TRUE\n",
    "    ) %T>%\n",
    "        write.csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-validate2.csv\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "readValidate2 = function (admethod = 'LeapTheory 4', write = FALSE) {\n",
    "\n",
    "    if (write)\n",
    "        write = writeValidate2()\n",
    "    \n",
    "    suppressMessages({suppressWarnings({\n",
    "        read_csv(\n",
    "            paste0(\n",
    "                \"..\\\\data\\\\df-\",\n",
    "                admethod %>% getShortenedAdmethodName(),\n",
    "                \"-2020-03-08.csv\"\n",
    "            )\n",
    "        ) %>%\n",
    "            select(-X1)\n",
    "    })}) %>% \n",
    "    convertDataTypes() %>%\n",
    "    processColumns() %>%\n",
    "    imputeMissingValues() %>%\n",
    "#     standardizeValues() %>% \n",
    "    keepModelFeatures()\n",
    "#     removeMissingObservations()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.validate2 = readValidate2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "upsampleImbalancedClassInTraining = function (df.train, upsample.multiple = 23, quietly = FALSE) {\n",
    "\n",
    "    ###  Upsample Minority Class (Funded == 1)  ###\n",
    "    if (!quietly) {\n",
    "        cat(\"Pre Upsample:\\n\")\n",
    "        print(df.train %>% group_by(funded) %>% summarize(n()))\n",
    "        cat('\\n')\n",
    "    }\n",
    "\n",
    "    train.funded = df.train %>% filter(funded == 'TRUE')\n",
    "    funded.rep.df = do.call(\n",
    "        rbind,\n",
    "        replicate(\n",
    "            n = upsample.multiple,\n",
    "            expr = {\n",
    "                rbind(data.frame(), train.funded)\n",
    "            },\n",
    "            simplify = FALSE\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    train.bal = rbind(\n",
    "        df.train,\n",
    "        funded.rep.df\n",
    "    )\n",
    "    \n",
    "    if (!quietly) {\n",
    "        cat(\"\\nPost Upsample:\\n\")\n",
    "        print(train.bal %>% group_by(funded) %>% summarize(n()))\n",
    "        cat('\\n')\n",
    "    }\n",
    "    \n",
    "    return(train.bal)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "removeNewClassesInGeneralization = function (df.generalize, df.train, generalize.name = NA) {\n",
    "    \n",
    "    df.similar = df.generalize %>%\n",
    "        filter(\n",
    "#             incometype %in% (df.train$incometype %>% unique()) &\n",
    "#             payrolltype %in% (df.train$payrolltype %>% unique()) &\n",
    "            statecode %in% (df.train$statecode %>% unique()) &\n",
    "#             campaign_id %in% (df.train$campaign_id %>% unique()) &\n",
    "            paycheck_direct_deposit %in% (df.train$paycheck_direct_deposit %>% unique()) &\n",
    "            srh_online_loan_opened_in_the_last_year %in% (df.train$srh_online_loan_opened_in_the_last_year %>% unique()) &\n",
    "            srh_online_loan_inquiry_in_the_last_thirty_days %in% (df.train$srh_online_loan_inquiry_in_the_last_thirty_days %>% unique()) &\n",
    "            ccr_worst_payment_rating_null %in% (df.train$ccr_worst_payment_rating_null %>% unique()) &\n",
    "            ccr_worst_payment_rating_plus %in% (df.train$ccr_worst_payment_rating_plus %>% unique()) &\n",
    "            ccr_worst_payment_rating_zero %in% (df.train$ccr_worst_payment_rating_zero %>% unique()) &\n",
    "            ccr_worst_payment_rating_hash %in% (df.train$ccr_worst_payment_rating_hash %>% unique()) &\n",
    "            ccr_worst_payment_rating_else %in% (df.train$ccr_worst_payment_rating_else %>% unique()) &\n",
    "            ccr_has_previous_loan_charged_off %in% (df.train$ccr_has_previous_loan_charged_off %>% unique())\n",
    "        )\n",
    "    \n",
    "    print(\n",
    "        paste0(\n",
    "            nrow(df.generalize) - nrow(df.similar),\n",
    "            ifelse(\n",
    "                is.na(generalize.name),\n",
    "                \" rows removed.\",\n",
    "                paste0(\" rows removed from \", generalize.name, \".\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cat(\"\\n\")\n",
    "    \n",
    "    return(df.similar)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "processAll = function (df.train, df.test, df.validate, df.validate2) {    \n",
    "    \n",
    "    list(\n",
    "        train = df.train %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        test = df.test %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"test set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        validate = df.validate %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"validation set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        validate2 = df.validate2 %>%\n",
    "            removeNewClassesInGeneralization(\n",
    "                df.train,\n",
    "                \"validation2 set\"\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            ),\n",
    "        \n",
    "        train.bal = df.train %>%\n",
    "            upsampleImbalancedClassInTraining(\n",
    "            ) %>% \n",
    "            mutate_if(\n",
    "                .predicate = ~ ! .x %>% is.numeric,\n",
    "                .funs = as.factor\n",
    "            ) %>% \n",
    "            select(\n",
    "                -statecode\n",
    "            )\n",
    "    )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split = processAll(\n",
    "    df.train,\n",
    "    df.test,\n",
    "    df.validate,\n",
    "    df.validate2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split$train.bal %>% str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getEvaluation = function (predict.object) {\n",
    "\n",
    "    detailed = predict.object %>% \n",
    "        as.data.frame(\n",
    "            stringsAsFactors = FALSE\n",
    "        ) %>% \n",
    "        group_by(\n",
    "            truth,\n",
    "            response\n",
    "        ) %>% \n",
    "        summarize(\n",
    "            n = n()\n",
    "        ) %>%\n",
    "        ungroup()\n",
    "    \n",
    "    prior = detailed %>% filter(truth == TRUE) %>% .$n %>% sum() /\n",
    "            detailed %>% .$n %>% sum()\n",
    "    \n",
    "    accuracy = detailed %>% filter(truth == response) %>% .$n %>% sum() /\n",
    "            detailed %>% .$n %>% sum()                              ##TP,TN\n",
    "    \n",
    "    recall = detailed %>% filter(truth == TRUE & response == TRUE) %>% .$n %>% sum()/\n",
    "            detailed %>% filter(truth == TRUE) %>% .$n %>% sum()    ##FP\n",
    "    \n",
    "    precision = detailed %>% filter(truth == TRUE & response == TRUE) %>% .$n %>% sum()/\n",
    "            detailed %>% filter(response == TRUE) %>% .$n %>% sum() ##FN\n",
    "    \n",
    "    \n",
    "    metrics = data.frame(\n",
    "        metric = c('prior', 'accuracy', 'recall', 'precision'),\n",
    "        value = c(prior, accuracy, recall, precision),\n",
    "        stringsAsFactors = FALSE\n",
    "    )\n",
    " \n",
    "    list(\n",
    "        detailed = detailed,\n",
    "        metrics = metrics\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getDecisionTree = function (data.split, evaluate = TRUE, xval = 0, minsplit = 1000, minbucket = 1000, cp = 0.00005) {\n",
    " \n",
    "\n",
    "    ####  Setup  ####\n",
    "\n",
    "    library(rattle)\n",
    "    # library(rpart)\n",
    "    # suppressWarnings({\n",
    "    #     listLearners() %>%\n",
    "    #         filter(\n",
    "    #             type == 'classif' &\n",
    "    #             name %>% str_detect('[Tt]ree')\n",
    "    #         )\n",
    "    # })\n",
    "    # getParamSet('classif.rpart')\n",
    "\n",
    "    # loss.matrix = matrix(\n",
    "    #     c(0,1,1.6,0),\n",
    "    #     byrow = TRUE,\n",
    "    #     nrow = 2\n",
    "    # )\n",
    "\n",
    "    rpart.task = makeClassifTask(\n",
    "        id = 'rpart.task',\n",
    "        data = data.split$train.bal %>%\n",
    "            select(\n",
    "                -newentered,\n",
    "                -qualified,\n",
    "                -funded_amount,\n",
    "                -type_formula,\n",
    "                -truefpd\n",
    "            ) %>% \n",
    "            select(\n",
    "#                 age,\n",
    "                ccr_score,\n",
    "#                 lead_day,\n",
    "                grossmonthlyincome,\n",
    "                requestedloanamount,\n",
    "                ccr_days_since_inquiry_previously_seen,\n",
    "                ccr_number_of_bank_accounts,\n",
    "                ticrh_ninety_days_ago,\n",
    "                funded\n",
    "            ),\n",
    "        target = 'funded',\n",
    "        positive = 'TRUE'\n",
    "    )\n",
    "\n",
    "    rpart.learner = makeLearner(\n",
    "        cl = 'classif.rpart',\n",
    "        id = 'rpart.learner',\n",
    "        xval = xval,                  ##  Number of Cross Validations\n",
    "        minsplit = minsplit,             ##  Number of Obs in Node for Split to be Attempted\n",
    "        minbucket = minbucket,             ##  Minimum number of observations in Leaf Node\n",
    "        cp = cp                ##  Minimum information gain for split to execute.\n",
    "    #     loss = loss.matrix\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Resampling  ####\n",
    "\n",
    "    # rpart.resample = makeResampleDesc('CV', iters = 5, stratify = TRUE)\n",
    "\n",
    "    # rpart.cv = resample(\n",
    "    #     learner = rpart.learner,\n",
    "    #     task = rpart.task,\n",
    "    #     resampling = rpart.resample,\n",
    "    #     measures = list(acc, mmce, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # # rpart.cv %>% .$measures.test\n",
    "    # # rpart.cv %>% .$aggr %>% as.data.frame()\n",
    "\n",
    "\n",
    "\n",
    "    ####  Hypertuning  ####\n",
    "\n",
    "    # rpart.params = makeParamSet(\n",
    "    #     makeIntegerParam('minsplit', lower = 10, upper = 50),\n",
    "    #     makeIntegerParam('minbucket', lower = 5, upper = 50),\n",
    "    #     makeNumericParam('cp', lower = 0.0001, upper = 0.2)\n",
    "    # )\n",
    "\n",
    "    # rpart.search = makeTuneControlGrid()\n",
    "\n",
    "    # rpart.tune = tuneParams(\n",
    "    #     learner = rpart.learner,\n",
    "    #     task = rpart.task,\n",
    "    #     resampling = rpart.resample,\n",
    "    #     par.set = rpart.params,\n",
    "    #     control = rpart.search,\n",
    "    #     measures = list(mmce, acc, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # setHyperPars(\n",
    "    #     learner = rpart.learner,\n",
    "    #     par.vals = rpart.tune$x\n",
    "    # ) \n",
    "\n",
    "\n",
    "\n",
    "    ####  Training  ####\n",
    "\n",
    "    rpart.model = train(\n",
    "        learner = rpart.learner,\n",
    "        task = rpart.task\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Evaluation  ####\n",
    "\n",
    "#     rpart.predict = predict(\n",
    "#         object = rpart.model,\n",
    "#         newdata = data.split$test %>% select(-newentered, -qualified)\n",
    "#     )\n",
    "\n",
    "#     rpart.validate = predict(\n",
    "#         object = rpart.model,\n",
    "#         newdata = data.split$validate %>% select(-newentered, -qualified)\n",
    "#     )\n",
    "\n",
    "#     test.eval = rpart.predict %>% getEvaluation()\n",
    "#     validate.eval = rpart.validate %>% getEvaluation()\n",
    "\n",
    "#     if (evaluate) {\n",
    "#         list(\n",
    "#             test.eval = test.eval,\n",
    "#             validate.eval = validate.eval\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "\n",
    "#     rules = rpart.model$learner.model\n",
    "#     rules.df = rpart.plot::rpart.rules(rpart.model$learner.model)\n",
    "# #     rules.tree = rpart.plot::rpart.plot(rpart.model$learner.model, type = 4)\n",
    "# #     fancyRpartPlot(rpart.model$learner.model)\n",
    "\n",
    "\n",
    "\n",
    "    ####  Outputs  ####\n",
    "    \n",
    "    ##    Tree    ##\n",
    "    pdf(\n",
    "        tf <- tempfile(\n",
    "            fileext = \".pdf\"\n",
    "        )\n",
    "    )\n",
    "    fancyRpartPlot(\n",
    "        rpart.model$learner.model\n",
    "    )\n",
    "    dev.off()\n",
    "    cat(tf)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings({suppressMessages({\n",
    "    data.split %>% getDecisionTree(evaluate = FALSE)\n",
    "})})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getDecisionTreeProposal = function (data.split, nodes.to.exclude.logic.expr, loantype = 'NEW') {    \n",
    "\n",
    "    \n",
    "    ####  Evaluation  ####\n",
    "    evaluatePerformance = function (data.split, stage, loantype.inner = loantype) {\n",
    "        \n",
    "        calculateChangeSize = function (metric.string, observed.metrics = observed, proposed.metrics = proposed) {\n",
    "            \n",
    "            (\n",
    "                100 *\n",
    "                ( proposed.metrics[[metric.string]] - observed.metrics[[metric.string]] ) /\n",
    "                observed.metrics[[metric.string]]\n",
    "            ) %>%\n",
    "            round(2) %>% \n",
    "            paste0('%')\n",
    "            \n",
    "        }\n",
    "        calculateChangeConversion = function (metric.string, observed.metrics = observed, proposed.metrics = proposed) {\n",
    "            \n",
    "            paste0(\n",
    "                ifelse(\n",
    "                    proposed.metrics[[metric.string]] - observed.metrics[[metric.string]] >= 0,\n",
    "                    '+',\n",
    "                    ''\n",
    "                ),\n",
    "                round(\n",
    "                    10000 * (proposed.metrics[[metric.string]] - observed.metrics[[metric.string]]),\n",
    "                    0\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        }\n",
    "        \n",
    "        observed = data.split[[stage]] %>%\n",
    "            filter(\n",
    "                parse(\n",
    "                    text = if_else(\n",
    "                        !is.na(loantype.inner),\n",
    "                        'str_to_upper(type_formula) == str_to_upper(loantype.inner) | is.na(type_formula)',\n",
    "                        'TRUE'\n",
    "                    )\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% \n",
    "            summarize(\n",
    "                accept.size = n(),\n",
    "                app.size = sum(newentered == 'TRUE'),\n",
    "                qual.size = sum(qualified == 'TRUE'),\n",
    "                funded.size = sum(funded == 'TRUE'),\n",
    "                dollar.size = sum(\n",
    "                    (funded == 'TRUE') *\n",
    "                    funded_amount,\n",
    "                    na.rm = TRUE\n",
    "                ),\n",
    "                \n",
    "                apply.rate = app.size/accept.size,\n",
    "                qr = qual.size/app.size,\n",
    "                fr = funded.size/qual.size,\n",
    "                app.to.fund = funded.size/app.size,\n",
    "                accept.to.fund = funded.size/accept.size,\n",
    "                \n",
    "                fpd.mature = sum(funded == 'TRUE' & !is.na(truefpd)) / funded.size,\n",
    "                fpd = sum(funded == 'TRUE' & !is.na(truefpd) & truefpd == 1) / sum(funded == 'TRUE' & !is.na(truefpd))\n",
    "            )\n",
    "\n",
    "        proposed = data.split[[stage]] %>%\n",
    "            filter(\n",
    "                !eval(nodes.to.exclude.logic.expr) &\n",
    "                parse(\n",
    "                    text = if_else(\n",
    "                        !is.na(loantype.inner),\n",
    "                        'str_to_upper(type_formula) == str_to_upper(loantype.inner) | is.na(type_formula)',\n",
    "                        'TRUE'\n",
    "                    )\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% \n",
    "            summarize(\n",
    "                accept.size = n(),\n",
    "                app.size = sum(newentered == 'TRUE'),\n",
    "                qual.size = sum(qualified == 'TRUE'),\n",
    "                funded.size = sum(funded == 'TRUE'),\n",
    "                dollar.size = sum(\n",
    "                    (funded == 'TRUE') *\n",
    "                    funded_amount,\n",
    "                    na.rm = TRUE\n",
    "                ),\n",
    "                \n",
    "                apply.rate = app.size/accept.size,\n",
    "                qr = qual.size/app.size,\n",
    "                fr = funded.size/qual.size,\n",
    "                app.to.fund = funded.size/app.size,\n",
    "                accept.to.fund = funded.size/accept.size,\n",
    "                \n",
    "                fpd.mature = sum(funded == 'TRUE' & !is.na(truefpd)) / funded.size,\n",
    "                fpd = sum(funded == 'TRUE' & !is.na(truefpd) & truefpd == 1) / sum(funded == 'TRUE' & !is.na(truefpd))\n",
    "            )\n",
    "\n",
    "        change = data.frame(\n",
    "            'Size__' = '',\n",
    "            accepted = 'accept.size' %>% calculateChangeSize(),\n",
    "            app = 'app.size' %>% calculateChangeSize(),\n",
    "            qualified = 'qual.size' %>% calculateChangeSize(),\n",
    "            funded = 'funded.size' %>% calculateChangeSize(),\n",
    "            funded.dollar = 'dollar.size' %>% calculateChangeSize(),\n",
    "            \n",
    "            'Rates__' = '',\n",
    "            apply.rate = 'apply.rate' %>% calculateChangeConversion(),\n",
    "            qr = 'qr' %>% calculateChangeConversion(),\n",
    "            fr = 'fr' %>% calculateChangeConversion(),\n",
    "            app.to.fund = 'app.to.fund' %>% calculateChangeConversion(),\n",
    "            accept.to.fund = 'accept.to.fund' %>% calculateChangeConversion(),\n",
    "            \n",
    "            fpd.mature = paste0(round(100*observed$fpd.mature, 2), '%'),\n",
    "            fpd = 'fpd' %>% calculateChangeConversion(),\n",
    "            \n",
    "            stringsAsFactors = FALSE\n",
    "        )\n",
    "        \n",
    "        list(\n",
    "#             observed = observed,\n",
    "#             proposed = proposed,\n",
    "            change = change\n",
    "        )\n",
    "        \n",
    "    }\n",
    "    \n",
    "    list(\n",
    "#         data.split %>% evaluatePerformance('train.bal'),\n",
    "        data.split %>% evaluatePerformance('train'),\n",
    "        data.split %>% evaluatePerformance('test'),\n",
    "        data.split %>% evaluatePerformance('validate'),\n",
    "        data.split %>% evaluatePerformance('validate2')\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "exclude.logic = expr(\n",
    "    (\n",
    "        ccr_score == 10000 &\n",
    "        ccr_number_of_bank_accounts == 10000\n",
    "#     ) |\n",
    "#     (\n",
    "#         requestedloanamount < 1450 &\n",
    "# #         ccr_number_of_bank_accounts >= 5.5\n",
    "#         ccr_number_of_bank_accounts == 10000\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "suppressWarnings({suppressMessages({\n",
    "    data.split %>% getDecisionTreeProposal(exclude.logic)\n",
    "})})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate Exclusion Nodes Generalization - Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "plotTimeSeries = function (admethod, exclude.logic.expr) {\n",
    "\n",
    "    df.ts = do.call(\n",
    "        what = rbind,\n",
    "        args = lapply(\n",
    "            X = c(\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2019-12-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-01-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-02-01.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-02-23.csv\"),\n",
    "                paste0(\"..\\\\data\\\\df-\", admethod %>% getShortenedAdmethodName, \"-2020-03-01.csv\")\n",
    "            ),\n",
    "            FUN = function (x) {\n",
    "                suppressWarnings({suppressMessages({read_csv(x)})})\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ###  Mix  ###\n",
    "    mix.plot = df.ts %>%\n",
    "        group_by(\n",
    "            lead_date = lead_time %>% as.Date()\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            day.total = n()\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        group_by(\n",
    "            lead_date,\n",
    "            exclude = eval(exclude.logic.expr)\n",
    "        ) %>% \n",
    "        summarize(\n",
    "            p = n()/mean(day.total)\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        ggplot(\n",
    "            mapping = aes(\n",
    "                x = lead_date,\n",
    "                y = p,\n",
    "                color = exclude\n",
    "            )\n",
    "        ) +\n",
    "        geom_line() +\n",
    "        geom_point() +\n",
    "        scale_y_continuous(\n",
    "            labels = scales::percent\n",
    "        ) +\n",
    "        labs(\n",
    "            title = \"Mix of Exclude\"\n",
    "        ) +\n",
    "        theme_bw()\n",
    "\n",
    "    ###  Conversion - FR  ###\n",
    "    conversion.plot = df.ts %>%\n",
    "        group_by(\n",
    "            lead_date = lead_time %>% as.Date(),\n",
    "            exclude = eval(exclude.logic.expr)\n",
    "        ) %>% \n",
    "        summarize(\n",
    "    #         conversion = sum(funded)/sum(qualified)\n",
    "    #         conversion = sum(qualified)/sum(newentered)\n",
    "    #         conversion = sum(newentered)/n()\n",
    "    #         conversion = sum(funded)/sum(newentered)\n",
    "            conversion = sum(funded)/n()\n",
    "        ) %>% \n",
    "        ungroup() %>% \n",
    "        ggplot(\n",
    "            mapping = aes(\n",
    "                x = lead_date,\n",
    "                y = conversion,\n",
    "                color = exclude\n",
    "            )\n",
    "        ) +\n",
    "        geom_line() +\n",
    "        geom_point() +\n",
    "        scale_y_continuous(\n",
    "            labels = scales::percent\n",
    "        ) +\n",
    "        labs(\n",
    "            title = \"Conversion of Exclude\"\n",
    "        ) +\n",
    "        theme_bw()\n",
    "\n",
    "    \n",
    "    list(\n",
    "        mix.plot,\n",
    "        conversion.plot\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CreditKarma4' %>% plotTimeSeries(exclude.logic.expr = exclude.logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getRemoveNALogic = function (data.split) {\n",
    "    \n",
    "    data.split$train.bal %>% \n",
    "        select(\n",
    "            -truefpd,\n",
    "            -type_formula,\n",
    "            -funded_amount\n",
    "        ) %>% \n",
    "        apply(\n",
    "            FUN = function (x) {x %>% is.na() %>% mean()},\n",
    "            MARGIN = 2\n",
    "        ) %>% \n",
    "        as.data.frame(\n",
    "        ) %>%\n",
    "        select(\n",
    "            perc = '.'\n",
    "        ) %>% \n",
    "        rownames_to_column(\n",
    "            'field'\n",
    "        ) %>% \n",
    "        filter(\n",
    "            perc > 0\n",
    "        ) %>% \n",
    "        mutate(\n",
    "            expression = field %>% \n",
    "                map(\n",
    "                    .f = ~ paste0(\n",
    "                        '!is.na(',\n",
    "                        .x,\n",
    "                        ')'\n",
    "                    )\n",
    "                ) %>% as.character()\n",
    "        ) %>% \n",
    "        .$expression %>% \n",
    "        paste0(\n",
    "            collapse = ' & '\n",
    "        )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "getRandomForest = function (\n",
    "    data.split,\n",
    "    evaluate = FALSE,\n",
    "    ntree = 24,\n",
    "    mtry = data.split$train.bal %>% ncol() %>% sqrt() %>% ceiling(),\n",
    "    replace = TRUE,\n",
    "#     cutoff = 1/2,\n",
    "#     sampsize = nrow(data.split$train.bal),\n",
    "    #     nodesize = 5,\n",
    "    oob.prox = FALSE\n",
    ") {\n",
    " \n",
    "\n",
    "    ####  Setup  ####\n",
    "\n",
    "    suppressWarnings({suppressMessages({\n",
    "        library(randomForest)\n",
    "    })})\n",
    "#     suppressWarnings({\n",
    "#         listLearners() %>%\n",
    "#             filter(\n",
    "#                 type == 'classif' &\n",
    "#                 name %>% str_detect('[Ff]orest')\n",
    "#             )\n",
    "#     })\n",
    "#     getParamSet('classif.randomForest')\n",
    "\n",
    "\n",
    "    ####  Task + Learner = Train  ####\n",
    "\n",
    "    rf.task = makeClassifTask(\n",
    "        id = 'rf.task',\n",
    "        data = data.split$train.bal %>%\n",
    "            select(\n",
    "                -newentered,\n",
    "                -qualified,\n",
    "                -funded_amount,\n",
    "                -type_formula,\n",
    "                -truefpd\n",
    "            ) %>% \n",
    "            filter(\n",
    "                parse(\n",
    "                    text = getRemoveNALogic(data.split = data.split)\n",
    "                ) %>%\n",
    "                eval()\n",
    "            ) %>% as.data.frame(),\n",
    "        target = 'funded',\n",
    "        positive = 'TRUE'\n",
    "    )\n",
    "\n",
    "    rf.learner = makeLearner(\n",
    "        cl = 'classif.randomForest',\n",
    "        id = 'rf.learner',\n",
    "        ntree = ntree,\n",
    "        mtry = mtry,\n",
    "        replace = replace,\n",
    "#         cutoff = cutoff,\n",
    "#         sampsize = sampsize,\n",
    "#         nodesize = nodesize,\n",
    "        oob.prox = FALSE\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Hypertuning  ####\n",
    "\n",
    "#     rf.resample = makeResampleDesc('CV', iters = 5, stratify = TRUE)\n",
    "\n",
    "#     rf.params = makeParamSet(\n",
    "#     #     makeIntegerParam('mtry', lower = 4, upper = 12),\n",
    "#     #     makeNumericParam('nodesize', lower = 10, upper = 11)\n",
    "#     )\n",
    "\n",
    "#     rf.search = makeTuneControlGrid()\n",
    "\n",
    "#     rf.tune = tuneParams(\n",
    "#         task = rf.task,\n",
    "#         learner = rf.learner,\n",
    "#         resampling = rf.resample,\n",
    "#         par.set = rf.params,\n",
    "#         control = rf.search,\n",
    "#         measures = list(mmce, acc, fpr),\n",
    "#         show.info = FALSE\n",
    "#     )\n",
    "\n",
    "#     rf.tune$x\n",
    "\n",
    "#     # setHyperPars(\n",
    "#     #     learner = rf.learner,\n",
    "#     #     par.vals = rf.tune$x\n",
    "#     # ) \n",
    "\n",
    "\n",
    "\n",
    "    ####  Resampling  ####\n",
    "\n",
    "    # rf.cv = resample(\n",
    "    #     learner = rf.learner,\n",
    "    #     task = rf.task,\n",
    "    #     resampling = rf.resample,\n",
    "    #     measures = list(acc, mmce, fpr),\n",
    "    #     show.info = FALSE\n",
    "    # )\n",
    "\n",
    "    # rf.cv %>% .$measures.test\n",
    "    # rf.cv %>% .$aggr %>% as.data.frame()\n",
    "\n",
    "\n",
    "\n",
    "    ####  Training  ####\n",
    "\n",
    "    rf.model = train(\n",
    "        learner = rf.learner,\n",
    "        task = rf.task\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    ####  Evaluation  ####\n",
    "\n",
    "#     rf.predict = predict(\n",
    "#         object = rf.model,\n",
    "#         newdata = data.split$test %>%\n",
    "#             select(\n",
    "#                 -newentered,\n",
    "#                 -qualified,\n",
    "#                 -funded_amount,\n",
    "#                 -type_formula,\n",
    "#                 -truefpd\n",
    "#             )\n",
    "#     )\n",
    "\n",
    "#     rf.validate = predict(\n",
    "#         object = rf.model,\n",
    "#         newdata = data.split$validate %>%\n",
    "#             select(\n",
    "#                 -newentered,\n",
    "#                 -qualified,\n",
    "#                 -funded_amount,\n",
    "#                 -type_formula,\n",
    "#                 -truefpd\n",
    "#             )\n",
    "#     )\n",
    "    \n",
    "#     test.eval = rf.predict %>% getEvaluation()\n",
    "#     validate.eval = rf.validate %>% getEvaluation()\n",
    "\n",
    "#     if (evaluate) {\n",
    "#         list(\n",
    "#             test.eval = test.eval,\n",
    "#             validate.eval = validate.eval\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "    ####  Outputs  ####\n",
    "    \n",
    "    ##    Model    ##\n",
    "    return(rf.model)\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "getVIP = function (rf.model) {\n",
    "    \n",
    "    df = rf.model$learner.model %>%\n",
    "        importance() %>%\n",
    "        as.data.frame() %>%\n",
    "        rownames_to_column(\n",
    "            var = 'variable'\n",
    "        ) %>%\n",
    "        arrange(\n",
    "            MeanDecreaseGini %>% desc()\n",
    "        )\n",
    "    \n",
    "    plot = rf.model$learner.model %>%\n",
    "        varImpPlot()\n",
    "    \n",
    "    list(\n",
    "        df = df,\n",
    "        plot = plot\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = data.split %>% getRandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf %>% getVIP()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
